#!/usr/bin/env python3
"""
Script de teste para o sistema Multi-LLM expandido com DeepSeek
Teste funcionalidades: DeepSeek, compara√ß√£o multi-LLM, recomenda√ß√£o de modelos
"""

import os
import sys
import json
from dotenv import load_dotenv
from typing import Dict, Any, List

# Carrega vari√°veis de ambiente
load_dotenv()

# Adiciona o diret√≥rio do projeto ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from llm_providers import LLMProviderManager

def test_deepseek_connection():
    """Testa conex√£o com DeepSeek"""
    print("üîç Testando conex√£o com DeepSeek...")
    
    deepseek_key = os.getenv("DEEPSEEK_API_KEY")
    if not deepseek_key:
        print("‚ö†Ô∏è  DEEPSEEK_API_KEY n√£o configurada")
        return False
    
    manager = LLMProviderManager()
    
    if "deepseek" not in manager.providers:
        print("‚ùå Provedor DeepSeek n√£o carregado")
        return False
    
    print("‚úÖ DeepSeek configurado com sucesso!")
    return True

def test_multi_llm_comparison():
    """Testa compara√ß√£o entre m√∫ltiplos LLMs"""
    print("\nüîÑ Testando compara√ß√£o Multi-LLM...")
    
    manager = LLMProviderManager()
    available_providers = manager.list_available_providers()
    
    if not available_providers:
        print("‚ùå Nenhum provedor configurado")
        return
    
    print(f"üìã Provedores dispon√≠veis: {available_providers}")
    
    # Pergunta simples para testar
    messages = [
        {"role": "user", "content": "Explique o que √© intelig√™ncia artificial em uma frase."}
    ]
    
    results = manager.compare_multi_llm(messages, max_tokens=100)
    
    print("\nüìä Resultados da compara√ß√£o:")
    for provider, result in results.items():
        if result["success"]:
            print(f"\nü§ñ {provider.upper()} ({result['model']}):")
            print(f"   Resposta: {result['response'][:100]}...")
            print(f"   Tempo: {result['duration']}s")
        else:
            print(f"\n‚ùå {provider.upper()}: {result.get('error', 'Erro desconhecido')}")

def test_provider_recommendations():
    """Testa sistema de recomenda√ß√£o de provedores"""
    print("\nüéØ Testando recomenda√ß√µes de provedores...")
    
    manager = LLMProviderManager()
    
    tasks = ["general", "coding", "creative", "analysis", "legal"]
    
    for task in tasks:
        best_provider = manager.get_best_provider_for_task(task)
        print(f"üìå Melhor para {task}: {best_provider}")

def test_provider_info():
    """Testa informa√ß√µes dos provedores"""
    print("\nüìã Informa√ß√µes dos provedores configurados:")
    
    manager = LLMProviderManager()
    info = manager.get_provider_info()
    
    print(json.dumps(info, indent=2, ensure_ascii=False))

def test_model_listing():
    """Testa listagem de modelos dispon√≠veis"""
    print("\nüìö Testando listagem de modelos...")
    
    manager = LLMProviderManager()
    
    for provider_name in manager.list_available_providers():
        try:
            models = manager.get_provider_models(provider_name)
            print(f"\nüîß {provider_name.upper()} - Modelos:")
            for model in models[:5]:  # Mostra apenas os primeiros 5
                print(f"   ‚Ä¢ {model}")
            if len(models) > 5:
                print(f"   ... e mais {len(models) - 5} modelos")
        except Exception as e:
            print(f"‚ùå Erro ao listar modelos para {provider_name}: {e}")

def main():
    """Fun√ß√£o principal de teste"""
    print("üöÄ Iniciando testes do sistema Multi-LLM expandido")
    print("=" * 60)
    
    # Teste 1: Conex√£o DeepSeek
    test_deepseek_connection()
    
    # Teste 2: Informa√ß√µes dos provedores
    test_provider_info()
    
    # Teste 3: Recomenda√ß√µes
    test_provider_recommendations()
    
    # Teste 4: Listagem de modelos
    test_model_listing()
    
    # Teste 5: Compara√ß√£o multi-LLM (opcional, requer APIs configuradas)
    response = input("\nü§î Executar teste de compara√ß√£o multi-LLM? (consome tokens) [y/N]: ")
    if response.lower() in ['y', 'yes', 's', 'sim']:
        test_multi_llm_comparison()
    
    print("\n‚úÖ Testes conclu√≠dos!")

if __name__ == "__main__":
    main() 