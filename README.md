# Sistema RAG com Agentes de IA

Um sistema completo de Retrieval-Augmented Generation (RAG) com agentes de IA, interface web e suporte a mÃºltiplos provedores de LLM.

## ğŸš€ Funcionalidades Principais

### ğŸ¤– Agentes de IA
- **Agentes Especializados**: Conversacional, Pesquisa, Executor de Tarefas
- **Agentes Customizados**: ConfigurÃ¡veis com prompts e parÃ¢metros especÃ­ficos
- **Agentes Multi-LLM**: Compare respostas de diferentes provedores em tempo real
- **MemÃ³ria de ConversaÃ§Ã£o**: Contexto mantido entre interaÃ§Ãµes
- **Sistema de Feedback**: Avalie a qualidade das respostas

### ğŸ“š Sistema RAG
- **Upload de Documentos**: PDF, DOCX, TXT, PPTX, XLSX
- **Processamento AutomÃ¡tico**: ExtraÃ§Ã£o e indexaÃ§Ã£o de conteÃºdo
- **Busca SemÃ¢ntica**: Encontre informaÃ§Ãµes relevantes nos documentos
- **Respostas Contextualizadas**: Baseadas no conhecimento dos documentos

### ğŸŒ Interface Web
- **Dashboard Interativo**: EstatÃ­sticas e monitoramento
- **Gerenciamento de Agentes**: CriaÃ§Ã£o, ediÃ§Ã£o e exclusÃ£o
- **Chat em Tempo Real**: Interface conversacional intuitiva
- **ComparaÃ§Ã£o Multi-LLM**: Visualize respostas lado a lado
- **Sistema de AvaliaÃ§Ã£o**: Like/dislike para feedback

### ğŸ”Œ MÃºltiplos Provedores de IA
- **OpenAI**: GPT-3.5, GPT-4, GPT-4o Mini
- **OpenRouter**: Acesso a mÃºltiplos modelos
- **Google Gemini**: Modelos do Google
- **Anthropic Claude**: Modelos Claude
- **Interface Unificada**: Troque entre provedores facilmente

## ğŸ†• Nova Funcionalidade: ComparaÃ§Ã£o Multi-LLM

### âœ¨ ComparaÃ§Ã£o em Tempo Real
- **MÃºltiplos LLMs SimultÃ¢neos**: Compare respostas de diferentes provedores
- **Interface Visual**: Respostas lado a lado com identificaÃ§Ã£o clara
- **EstatÃ­sticas de ComparaÃ§Ã£o**: Tamanho, unicidade e diferenÃ§as
- **SeleÃ§Ã£o FlexÃ­vel**: Escolha quais provedores usar

### ğŸ¯ Como Usar
1. **Ative o Modo Multi-LLM**: Marque a caixa "Comparar MÃºltiplos LLMs"
2. **Selecione Provedores**: Escolha quais LLMs comparar
3. **FaÃ§a sua Pergunta**: Digite normalmente
4. **Compare Respostas**: Veja todas as respostas lado a lado
5. **Avalie**: Use os botÃµes de feedback para cada resposta

### ğŸ“Š BenefÃ­cios
- **Melhor Qualidade**: Identifique qual LLM oferece melhores respostas
- **OtimizaÃ§Ã£o de Custos**: Compare performance vs. custo
- **Flexibilidade**: Troque entre provedores conforme necessÃ¡rio
- **AnÃ¡lise Comparativa**: Entenda diferenÃ§as entre modelos

## ğŸ› ï¸ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- PostgreSQL com extensÃ£o pgvector
- Contas nos provedores de IA desejados

### 1. Clone o RepositÃ³rio
```bash
git clone <repository-url>
cd rag_python
```

### 2. Instale as DependÃªncias
```bash
pip install -r requirements.txt
```

### 3. Configure as VariÃ¡veis de Ambiente
Crie um arquivo `.env` baseado no `env.example`:

```bash
# Banco de Dados PostgreSQL
DATABASE_URL=postgresql://user:password@localhost:5432/rag_system

# Provedores de IA
OPENAI_API_KEY=your_openai_key
OPENROUTER_API_KEY=your_openrouter_key
GOOGLE_API_KEY=your_google_key
ANTHROPIC_API_KEY=your_anthropic_key

# ConfiguraÃ§Ãµes do Sistema
FLASK_SECRET_KEY=your_secret_key
```

### 4. Configure o Banco de Dados
```bash
# Execute o script SQL para criar as tabelas
psql -d your_database -f schema.sql
```

### 5. Inicialize o Sistema
```bash
python web_agent_manager.py
```

## ğŸš€ Uso RÃ¡pido

### 1. Acesse a Interface Web
```
http://localhost:5000
```

### 2. Crie um Agente
- VÃ¡ para "Agentes" â†’ "Criar Novo Agente"
- Configure nome, descriÃ§Ã£o e parÃ¢metros
- Selecione o provedor de IA desejado

### 3. FaÃ§a Upload de Documentos
- Acesse o agente criado
- Use a seÃ§Ã£o "Upload de Arquivos"
- Selecione documentos PDF, DOCX, etc.

### 4. Teste a ComparaÃ§Ã£o Multi-LLM
- Ative o modo "Comparar MÃºltiplos LLMs"
- Selecione os provedores desejados
- FaÃ§a perguntas e compare as respostas

### 5. Monitore o Desempenho
- Use o dashboard para ver estatÃ­sticas
- Avalie respostas com o sistema de feedback
- Acompanhe mÃ©tricas por agente

## ğŸ“– DocumentaÃ§Ã£o Detalhada

### ConfiguraÃ§Ã£o de Provedores
Veja [PROVIDERS_SETUP.md](PROVIDERS_SETUP.md) para configuraÃ§Ã£o detalhada dos provedores de IA.

### Fluxo de Documentos
Veja [FLUXO_DOCUMENTOS.md](FLUXO_DOCUMENTOS.md) para entender como os documentos sÃ£o processados.

### Sistema de Agentes
Veja [README_AGENTS.md](README_AGENTS.md) para detalhes sobre os tipos de agentes.

## ğŸ§ª Testes

### Teste Multi-LLM
```bash
python test_multi_llm.py
```

### Teste de Provedores
```bash
python test_providers.py
```

### Teste do Sistema RAG
```bash
python test_server.py
```

## ğŸ“Š Estrutura do Projeto

```
rag_python/
â”œâ”€â”€ web_agent_manager.py      # Servidor web principal
â”œâ”€â”€ agent_system.py           # Sistema de agentes
â”œâ”€â”€ rag_system.py            # Sistema RAG
â”œâ”€â”€ llm_providers.py         # Gerenciador de provedores
â”œâ”€â”€ database.py              # ConexÃ£o com banco de dados
â”œâ”€â”€ vector_store.py          # Armazenamento de vetores
â”œâ”€â”€ document_loader.py       # Carregamento de documentos
â”œâ”€â”€ templates/               # Templates HTML
â”œâ”€â”€ agent_uploads/           # Arquivos dos agentes
â”œâ”€â”€ agent_vector_dbs/        # Bancos de vetores
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â”œâ”€â”€ schema.sql              # Schema do banco de dados
â””â”€â”€ docs/                   # DocumentaÃ§Ã£o
```

## ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas

### PersonalizaÃ§Ã£o de Agentes
```python
from agent_system import create_agent

# Agente customizado
agent = create_agent("custom", 
    name="Meu Agente",
    system_prompt="VocÃª Ã© um especialista em...",
    model_name="gpt-4",
    temperature=0.7,
    provider="openai"
)

# Agente multi-LLM
multi_agent = create_agent("multi_llm",
    name="Comparador",
    providers=["openai", "openrouter", "gemini"],
    model_name="gpt-3.5-turbo"
)
```

### ConfiguraÃ§Ã£o de Provedores
```python
from llm_providers import llm_manager

# Configurar provedor ativo
llm_manager.set_active_provider("openai")

# Obter informaÃ§Ãµes dos provedores
providers = llm_manager.get_provider_info()
models = llm_manager.get_provider_models("openai")
```

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ†˜ Suporte

- **Issues**: Use o GitHub Issues para reportar bugs
- **DocumentaÃ§Ã£o**: Consulte os arquivos README especÃ­ficos
- **Exemplos**: Veja a pasta `examples/` para casos de uso

## ğŸ¯ Roadmap

- [ ] Suporte a mais formatos de documento
- [ ] IntegraÃ§Ã£o com mais provedores de IA
- [ ] Sistema de plugins para agentes
- [ ] API REST completa
- [ ] Interface mobile
- [ ] AnÃ¡lise avanÃ§ada de performance
- [ ] Sistema de backup automÃ¡tico
- [ ] IntegraÃ§Ã£o com ferramentas externas

---

**Desenvolvido com â¤ï¸ para facilitar o uso de IA em aplicaÃ§Ãµes prÃ¡ticas**
