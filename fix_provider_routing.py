#!/usr/bin/env python3
"""
ğŸ”§ CORREÃ‡ÃƒO DO ROTEAMENTO DE PROVEDORES LLM
Corrige o problema onde modelos de diferentes provedores sÃ£o enviados para OpenAI
"""

import os
import re

def fix_llm_routing():
    """Corrige o roteamento de provedores no arquivo llm_providers.py"""
    
    # Ler arquivo original
    with open('llm_providers.py', 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Fazer backup
    with open('llm_providers.py.backup', 'w', encoding='utf-8') as f:
        f.write(content)
    
    # Aplicar correÃ§Ãµes especÃ­ficas
    corrections = [
        # Corrigir variÃ¡vel de ambiente do Google
        ('GOOGLE_GEMINI_API_KEY', 'GOOGLE_API_KEY'),
        
        # Corrigir nome do provedor Google no dicionÃ¡rio
        ('self.providers["gemini"]', 'self.providers["google"]'),
        ('self.active_provider = "gemini"', 'self.active_provider = "google"'),
        
        # Corrigir nome do provedor na configuraÃ§Ã£o
        ('name="gemini"', 'name="google"'),
    ]
    
    for old, new in corrections:
        content = content.replace(old, new)
    
    # Adicionar validaÃ§Ã£o de modelo por provedor
    validation_code = '''
    def _validate_model_for_provider(self, provider_name: str, model: str) -> str:
        """Valida se o modelo Ã© compatÃ­vel com o provedor"""
        
        # Mapeamento de modelos por provedor
        provider_models = {
            'openai': ['gpt-4o', 'gpt-4o-mini', 'gpt-4-turbo', 'gpt-4', 'gpt-3.5-turbo', 'gpt-3.5-turbo-16k'],
            'google': ['gemini-1.5-pro', 'gemini-1.5-flash', 'gemini-pro', 'gemini-pro-vision'],
            'openrouter': ['openai/gpt-4o', 'openai/gpt-4o-mini', 'anthropic/claude-3.5-sonnet', 
                          'anthropic/claude-3-haiku', 'meta-llama/llama-3.1-405b-instruct'],
            'deepseek': ['deepseek-chat', 'deepseek-coder', 'deepseek-math']
        }
        
        # Se o provedor nÃ£o tem modelos mapeados, usar modelo padrÃ£o
        if provider_name not in provider_models:
            return self.providers[provider_name].config.model_name
        
        # Se o modelo nÃ£o Ã© compatÃ­vel com o provedor, usar modelo padrÃ£o
        valid_models = provider_models[provider_name]
        if model not in valid_models:
            return self.providers[provider_name].config.model_name
        
        return model
'''
    
    # Inserir a funÃ§Ã£o de validaÃ§Ã£o antes da funÃ§Ã£o generate_response
    pattern = r'(def generate_response\(self, messages: List\[Dict\[str, str\]\], provider_name: str = None, \*\*kwargs\) -> Dict\[str, Any\]:)'
    content = re.sub(pattern, validation_code + '\n    \\1', content)
    
    # Modificar a funÃ§Ã£o generate_response para usar validaÃ§Ã£o
    old_generate = '''            # Gerar resposta
            response = provider.generate_response(messages, **kwargs)'''
    
    new_generate = '''            # Validar modelo para o provedor
            model = kwargs.get('model')
            if model:
                validated_model = self._validate_model_for_provider(provider_name or self.active_provider, model)
                kwargs['model'] = validated_model
            
            # Gerar resposta
            response = provider.generate_response(messages, **kwargs)'''
    
    content = content.replace(old_generate, new_generate)
    
    # Salvar arquivo corrigido
    with open('llm_providers.py', 'w', encoding='utf-8') as f:
        f.write(content)
    
    print("âœ… CorreÃ§Ãµes aplicadas em llm_providers.py")
    print("ğŸ“„ Backup salvo como llm_providers.py.backup")

def create_provider_test():
    """Cria um script de teste para os provedores"""
    
    test_code = '''#!/usr/bin/env python3
"""
ğŸ§ª TESTE DOS PROVEDORES LLM CORRIGIDOS
"""

import os
import sys
from llm_providers import LLMProviderManager

def test_providers():
    """Testa os provedores com modelos corretos"""
    
    manager = LLMProviderManager()
    
    # Testes por provedor
    tests = [
        # OpenAI (deve funcionar)
        ("openai", "gpt-3.5-turbo", "OlÃ¡, como vocÃª estÃ¡ funcionando?"),
        ("openai", "gpt-4o-mini", "Teste modelo gpt-4o-mini"),
        
        # Google (sÃ³ se configurado)
        ("google", "gemini-1.5-flash", "Teste Google Gemini"),
        
        # OpenRouter (sÃ³ se configurado)  
        ("openrouter", "openai/gpt-4o-mini", "Teste OpenRouter"),
        
        # DeepSeek (sÃ³ se configurado)
        ("deepseek", "deepseek-chat", "Teste DeepSeek"),
    ]
    
    results = []
    
    for provider, model, message in tests:
        print(f"\\nğŸ§ª Testando {provider} com modelo {model}...")
        
        try:
            result = manager.generate_response(
                messages=[{"role": "user", "content": message}],
                provider_name=provider,
                model=model
            )
            
            if result['success']:
                print(f"âœ… {provider}: {result['response'][:100]}...")
                results.append((provider, model, True, None))
            else:
                print(f"âŒ {provider}: {result['error']}")
                results.append((provider, model, False, result['error']))
                
        except Exception as e:
            print(f"âŒ {provider}: Erro - {e}")
            results.append((provider, model, False, str(e)))
    
    # Resumo
    print("\\n" + "="*60)
    print("ğŸ“Š RESUMO DOS TESTES")
    print("="*60)
    
    success_count = 0
    for provider, model, success, error in results:
        status = "âœ…" if success else "âŒ"
        print(f"{status} {provider} ({model})")
        if success:
            success_count += 1
    
    print(f"\\nğŸ¯ Resultado: {success_count}/{len(results)} testes passaram")
    
    return success_count > 0

if __name__ == "__main__":
    success = test_providers()
    sys.exit(0 if success else 1)
'''
    
    with open('test_providers_fixed.py', 'w', encoding='utf-8') as f:
        f.write(test_code)
    
    print("âœ… Script de teste criado: test_providers_fixed.py")

def main():
    """Executa todas as correÃ§Ãµes"""
    print("ğŸš€ CORREÃ‡ÃƒO DO ROTEAMENTO DE PROVEDORES LLM")
    print("=" * 60)
    
    # 1. Corrigir roteamento
    print("1ï¸âƒ£ Corrigindo roteamento de provedores...")
    fix_llm_routing()
    
    # 2. Criar teste
    print("\\n2ï¸âƒ£ Criando script de teste...")
    create_provider_test()
    
    # 3. Verificar API Keys
    print("\\n3ï¸âƒ£ Status das API Keys:")
    keys = {
        'OPENAI_API_KEY': 'OpenAI',
        'GOOGLE_API_KEY': 'Google Gemini', 
        'OPENROUTER_API_KEY': 'OpenRouter',
        'DEEPSEEK_API_KEY': 'DeepSeek'
    }
    
    configured = 0
    for env_var, name in keys.items():
        value = os.getenv(env_var)
        if value:
            print(f"âœ… {name}: Configurada")
            configured += 1
        else:
            print(f"âŒ {name}: NÃƒO configurada")
    
    print(f"\\nğŸ“Š Total: {configured}/{len(keys)} API Keys configuradas")
    
    # 4. RecomendaÃ§Ãµes
    print("\\n" + "=" * 60)
    print("ğŸ’¡ PRÃ“XIMOS PASSOS:")
    print("ğŸ”„ Reinicie o servidor Streamlit")
    print("ğŸ§ª Execute: python test_providers_fixed.py")
    print("ğŸŒ Teste na interface Multi-LLM")
    
    if configured < 2:
        print("\\nâš ï¸ RECOMENDAÃ‡ÃƒO:")
        print("Configure mais API Keys para testar outros provedores:")
        print("â€¢ OpenRouter: https://openrouter.ai/")
        print("â€¢ DeepSeek: https://platform.deepseek.com/")
        print("â€¢ Google AI: https://makersuite.google.com/")

if __name__ == "__main__":
    main() 