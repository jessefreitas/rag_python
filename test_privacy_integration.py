#!/usr/bin/env python3
"""
Teste do Sistema Integrado: Multi-LLM + Privacidade + Agentes
ValidaÃ§Ã£o completa do sistema RAG Python com compliance LGPD
"""

import os
import sys
import json
from datetime import datetime, timedelta
from dotenv import load_dotenv

# Carrega variÃ¡veis de ambiente
load_dotenv()

# Adiciona o diretÃ³rio do projeto ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from agent_system_privacy import privacy_agent_system, PrivacyAwareAgent
from privacy_system import privacy_manager, DataCategory, RetentionPolicy
from llm_providers import llm_manager

def test_privacy_agent_creation():
    """Testa criaÃ§Ã£o de agentes com diferentes nÃ­veis de privacidade"""
    print("ğŸ” Testando criaÃ§Ã£o de agentes com privacidade...")
    
    # Agente padrÃ£o
    agent_standard = privacy_agent_system.create_privacy_agent(
        name="Agente JurÃ­dico PadrÃ£o",
        description="AnÃ¡lise de documentos jurÃ­dicos com privacidade padrÃ£o",
        system_prompt="VocÃª Ã© um assistente jurÃ­dico especializado em anÃ¡lise de contratos.",
        privacy_level="standard"
    )
    
    # Agente alta privacidade
    agent_high = privacy_agent_system.create_privacy_agent(
        name="Agente LGPD Alto",
        description="Processamento de dados pessoais com alta privacidade",
        system_prompt="VocÃª Ã© um assistente especializado em compliance LGPD.",
        privacy_level="high"
    )
    
    # Agente mÃ¡xima privacidade
    agent_maximum = privacy_agent_system.create_privacy_agent(
        name="Agente Dados SensÃ­veis",
        description="Processamento de dados sensÃ­veis com mÃ¡xima privacidade",
        system_prompt="VocÃª Ã© um assistente para dados mÃ©dicos e sensÃ­veis.",
        privacy_level="maximum"
    )
    
    print(f"âœ… Criados 3 agentes:")
    print(f"   ğŸ“‹ {agent_standard.name} (ID: {agent_standard.agent_id[:8]}...) - {agent_standard.privacy_level}")
    print(f"   ğŸ”’ {agent_high.name} (ID: {agent_high.agent_id[:8]}...) - {agent_high.privacy_level}")
    print(f"   ğŸ›¡ï¸  {agent_maximum.name} (ID: {agent_maximum.agent_id[:8]}...) - {agent_maximum.privacy_level}")
    
    return agent_standard, agent_high, agent_maximum

def test_document_processing_with_privacy():
    """Testa processamento de documentos com dados pessoais"""
    print("\nğŸ“„ Testando processamento de documentos com privacidade...")
    
    # Documento com dados pessoais
    document_content = """
    CONTRATO DE PRESTAÃ‡ÃƒO DE SERVIÃ‡OS
    
    Contratante: JoÃ£o Silva Santos
    CPF: 123.456.789-10
    E-mail: joao.silva@email.com
    Telefone: (11) 98765-4321
    EndereÃ§o: Rua das Flores, 123, CEP: 01234-567, SÃ£o Paulo, SP
    
    Este contrato estabelece os termos para prestaÃ§Ã£o de serviÃ§os jurÃ­dicos...
    """
    
    agents = privacy_agent_system.agents
    
    for agent_id, agent in list(agents.items())[:3]:  # Testa apenas os 3 primeiros
        if isinstance(agent, PrivacyAwareAgent):
            print(f"\nğŸ¤– Testando {agent.name} ({agent.privacy_level}):")
            
            # Teste sem consentimento
            result_no_consent = agent.process_document_with_privacy(
                content=document_content,
                filename="contrato_teste.txt",
                user_consent=False,
                processing_purpose="AnÃ¡lise de contrato"
            )
            
            if result_no_consent['success']:
                print(f"   âœ… Processado com sucesso")
                print(f"   ğŸ“Š Dados detectados: {list(result_no_consent['privacy_info']['detected_data'].keys())}")
                print(f"   ğŸ”’ AnonimizaÃ§Ã£o: {'Sim' if result_no_consent['privacy_info']['anonymization_applied'] else 'NÃ£o'}")
            else:
                print(f"   âš ï¸  Falhou: {result_no_consent.get('error', 'Erro desconhecido')}")
                
                # Se falhou por falta de consentimento, tenta com consentimento
                if result_no_consent.get('consent_required'):
                    print(f"   ğŸ”„ Tentando novamente com consentimento...")
                    result_with_consent = agent.process_document_with_privacy(
                        content=document_content,
                        filename="contrato_teste.txt",
                        user_consent=True,
                        processing_purpose="AnÃ¡lise de contrato"
                    )
                    
                    if result_with_consent['success']:
                        print(f"   âœ… Processado com consentimento")
                        print(f"   ğŸ“Š Dados detectados: {list(result_with_consent['privacy_info']['detected_data'].keys())}")

def test_query_with_personal_data():
    """Testa queries com dados pessoais"""
    print("\nâ“ Testando queries com dados pessoais...")
    
    personal_query = "Analise o contrato do JoÃ£o Silva (CPF 123.456.789-10) e me diga se hÃ¡ clÃ¡usulas abusivas."
    
    agents = list(privacy_agent_system.agents.values())[:2]  # Testa 2 agentes
    
    for agent in agents:
        if isinstance(agent, PrivacyAwareAgent):
            print(f"\nğŸ¤– {agent.name} ({agent.privacy_level}):")
            
            result = agent.query_with_privacy(
                query=personal_query,
                user_consent=True  # Fornece consentimento
            )
            
            if result['success']:
                print(f"   âœ… Query processada")
                print(f"   ğŸ“Š Dados detectados: {list(result['privacy_info']['detected_data'].keys())}")
                print(f"   ğŸ”’ AnonimizaÃ§Ã£o: {'Sim' if result['privacy_info']['anonymization_applied'] else 'NÃ£o'}")
            else:
                print(f"   âŒ Falhou: {result.get('error', 'Erro desconhecido')}")

def test_privacy_reports():
    """Testa geraÃ§Ã£o de relatÃ³rios de privacidade"""
    print("\nğŸ“Š Testando relatÃ³rios de privacidade...")
    
    # RelatÃ³rio individual de um agente
    agents = list(privacy_agent_system.agents.values())
    if agents:
        agent = agents[0]
        if isinstance(agent, PrivacyAwareAgent):
            report = agent.get_privacy_report()
            print(f"\nğŸ“‹ RelatÃ³rio do {agent.name}:")
            print(f"   ğŸ“Š Documentos processados: {report['stats']['documents_processed']}")
            print(f"   ğŸ”’ Dados anonimizados: {report['stats']['data_anonymized']}")
            print(f"   âš ï¸  ViolaÃ§Ãµes de compliance: {report['stats']['compliance_violations']}")
            print(f"   ğŸ“ Total de registros: {report['data_records']['total']}")
    
    # RelatÃ³rio do sistema
    system_report = privacy_agent_system.get_system_privacy_report()
    print(f"\nğŸ¢ RelatÃ³rio do Sistema:")
    print(f"   ğŸ¤– Total de agentes: {system_report['compliance_summary']['total_agents']}")
    print(f"   ğŸ“ Total de registros: {system_report['compliance_summary']['total_data_records']}")
    print(f"   âœ… Registros ativos: {system_report['compliance_summary']['active_records']}")
    print(f"   âš ï¸  ViolaÃ§Ãµes: {system_report['compliance_summary']['compliance_violations']}")

def test_data_lifecycle():
    """Testa ciclo de vida dos dados"""
    print("\nğŸ”„ Testando ciclo de vida dos dados...")
    
    # Cria dados de teste com retenÃ§Ã£o curta
    from privacy_system import DataRecord
    
    test_content = "Documento de teste com CPF 999.888.777-66 para validaÃ§Ã£o."
    
    # Cria registro com retenÃ§Ã£o curta (simula expiraÃ§Ã£o)
    record = privacy_manager.create_data_record(
        content=test_content,
        agent_id="test_agent",
        purpose="Teste de ciclo de vida",
        retention_policy=RetentionPolicy.SHORT_TERM
    )
    
    print(f"   ğŸ“ Registro criado: {record.id[:8]}...")
    print(f"   ğŸ“… Expira em: {record.expires_at}")
    print(f"   ğŸ“Š Categoria: {record.category.value}")
    
    # Testa anonimizaÃ§Ã£o manual
    success = privacy_manager.anonymize_record(record.id, method="masking")
    if success:
        print(f"   ğŸ”’ Registro anonimizado com sucesso")
        updated_record = privacy_manager.data_records[record.id]
        print(f"   ğŸ“Š Nova categoria: {updated_record.category.value}")
    
    # Testa soft delete
    success = privacy_manager.soft_delete_record(record.id, "Teste de exclusÃ£o")
    if success:
        print(f"   ğŸ—‘ï¸  Soft delete aplicado")

def test_compliance_cleanup():
    """Testa limpeza automÃ¡tica de compliance"""
    print("\nğŸ§¹ Testando limpeza automÃ¡tica...")
    
    # Executa limpeza
    cleanup_result = privacy_agent_system.run_privacy_cleanup()
    
    print(f"   ğŸ•’ Ãšltima limpeza: {cleanup_result['cleanup_timestamp']}")
    print(f"   ğŸ“Š EstatÃ­sticas:")
    print(f"      - Anonimizados: {cleanup_result['stats']['anonymized']}")
    print(f"      - ExcluÃ­dos: {cleanup_result['stats']['hard_deleted']}")
    print(f"      - Ignorados: {cleanup_result['stats']['skipped']}")
    print(f"   â° PrÃ³xima limpeza: {cleanup_result['next_cleanup']}")

def test_multi_llm_with_privacy():
    """Testa integraÃ§Ã£o Multi-LLM com privacidade"""
    print("\nğŸ¤– Testando Multi-LLM com privacidade...")
    
    available_providers = llm_manager.list_available_providers()
    print(f"   ğŸ“‹ Provedores disponÃ­veis: {available_providers}")
    
    if available_providers:
        # Testa recomendaÃ§Ã£o para tarefa jurÃ­dica
        best_for_legal = llm_manager.get_best_provider_for_task("legal")
        print(f"   âš–ï¸  Melhor para jurÃ­dico: {best_for_legal}")
        
        # Cria agente com o melhor provedor
        if best_for_legal:
            privacy_agent = privacy_agent_system.create_privacy_agent(
                name="Agente Multi-LLM JurÃ­dico",
                description="Agente jurÃ­dico com melhor LLM disponÃ­vel",
                system_prompt="VocÃª Ã© um assistente jurÃ­dico especializado.",
                model_name=best_for_legal,
                privacy_level="high"
            )
            print(f"   âœ… Agente criado com {best_for_legal}")

def main():
    """FunÃ§Ã£o principal de teste"""
    print("ğŸš€ Iniciando testes do sistema integrado RAG Python")
    print("=" * 70)
    print("ğŸ”§ Multi-LLM + ğŸ” Privacidade + ğŸ¤– Agentes + âš–ï¸  LGPD")
    print("=" * 70)
    
    try:
        # Teste 1: CriaÃ§Ã£o de agentes
        agents = test_privacy_agent_creation()
        
        # Teste 2: Processamento de documentos
        test_document_processing_with_privacy()
        
        # Teste 3: Queries com dados pessoais
        test_query_with_personal_data()
        
        # Teste 4: RelatÃ³rios de privacidade
        test_privacy_reports()
        
        # Teste 5: Ciclo de vida dos dados
        test_data_lifecycle()
        
        # Teste 6: Limpeza automÃ¡tica
        test_compliance_cleanup()
        
        # Teste 7: IntegraÃ§Ã£o Multi-LLM
        test_multi_llm_with_privacy()
        
        print("\n" + "=" * 70)
        print("âœ… TODOS OS TESTES CONCLUÃDOS COM SUCESSO!")
        print("ğŸ¯ Sistema RAG Python completamente integrado e funcional")
        print("ğŸ” Compliance LGPD ativo")
        print("ğŸ¤– Multi-LLM operacional")
        print("âš–ï¸  Agentes jurÃ­dicos com privacidade")
        
    except Exception as e:
        print(f"\nâŒ ERRO durante os testes: {e}")
        import traceback
        traceback.print_exc()
        
    print("\nğŸ“‹ Resumo do sistema:")
    summary = privacy_agent_system.get_system_privacy_report()
    print(f"   ğŸ¤– Agentes ativos: {summary['compliance_summary']['total_agents']}")
    print(f"   ğŸ“ Registros de dados: {summary['compliance_summary']['total_data_records']}")
    print(f"   âš ï¸  ViolaÃ§Ãµes: {summary['compliance_summary']['compliance_violations']}")

if __name__ == "__main__":
    main() 