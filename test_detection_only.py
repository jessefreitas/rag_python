#!/usr/bin/env python3
"""
Teste do Modo DetecÃ§Ã£o Apenas - RAG Python
ValidaÃ§Ã£o da detecÃ§Ã£o de dados pessoais SEM anonimizaÃ§Ã£o
"""

import os
import sys
import json
from dotenv import load_dotenv

# Carrega variÃ¡veis de ambiente
load_dotenv()

# Adiciona o diretÃ³rio do projeto ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from agent_system_privacy import privacy_agent_system, PrivacyAwareAgent
from privacy_system import privacy_manager

def test_detection_only_functionality():
    """Testa funcionalidades bÃ¡sicas de detecÃ§Ã£o apenas"""
    print("ğŸ” Testando funcionalidades de detecÃ§Ã£o apenas...")
    
    # Documento de teste com vÃ¡rios tipos de dados pessoais
    test_document = """
    RELATÃ“RIO MÃ‰DICO CONFIDENCIAL
    
    Paciente: Maria Silva Santos
    CPF: 123.456.789-10
    RG: 12.345.678-9
    E-mail: maria.silva@email.com
    Telefone: (11) 98765-4321
    EndereÃ§o: Rua das Flores, 123, CEP: 01234-567, SÃ£o Paulo, SP
    
    CNPJ da ClÃ­nica: 12.345.678/0001-90
    
    DiagnÃ³stico: O paciente apresenta sintomas compatÃ­veis com...
    Tratamento recomendado: MedicaÃ§Ã£o especÃ­fica para...
    """
    
    # 1. Teste bÃ¡sico de detecÃ§Ã£o
    print("\nğŸ“‹ 1. Teste bÃ¡sico de detecÃ§Ã£o:")
    detection_result = privacy_manager.detect_personal_data_only(test_document, detailed=True)
    
    print(f"   ğŸ“Š Dados pessoais detectados: {'SIM' if detection_result['has_personal_data'] else 'NÃƒO'}")
    print(f"   ğŸ“‚ Categoria: {detection_result['data_category']}")
    print(f"   ğŸ”¢ Total de ocorrÃªncias: {detection_result['total_occurrences']}")
    print(f"   ğŸ“ Tipos detectados: {', '.join(detection_result['detected_types'])}")
    
    if detection_result.get('details'):
        print("\n   ğŸ“‹ Detalhes por tipo:")
        for data_type, details in detection_result['details'].items():
            print(f"      {data_type.upper()}: {details['count']} ocorrÃªncias")
            print(f"         Exemplos: {details['examples']}")
    
    # 2. Teste de anÃ¡lise de riscos
    print("\nâš ï¸  2. AnÃ¡lise de riscos de privacidade:")
    risk_analysis = privacy_manager.analyze_document_privacy_risks(test_document)
    
    print(f"   ğŸ¯ NÃ­vel de risco: {risk_analysis['risk_level']}")
    print(f"   ğŸ“Š Score de risco: {risk_analysis['risk_score']}")
    print(f"   ğŸ“ DescriÃ§Ã£o: {risk_analysis['risk_description']}")
    print(f"   âš–ï¸  Compliance LGPD obrigatÃ³rio: {'SIM' if risk_analysis['lgpd_compliance_required'] else 'NÃƒO'}")
    
    print("\n   ğŸ’¡ RecomendaÃ§Ãµes:")
    for rec in risk_analysis['recommendations']:
        print(f"      - {rec}")
    
    return detection_result, risk_analysis

def test_detection_only_agent():
    """Testa agente configurado apenas para detecÃ§Ã£o"""
    print("\nğŸ¤– Testando agente em modo detecÃ§Ã£o apenas...")
    
    # Cria agente especÃ­fico para detecÃ§Ã£o
    detection_agent = privacy_agent_system.create_privacy_agent(
        name="Agente DetecÃ§Ã£o JurÃ­dica",
        description="Agente que detecta dados pessoais sem anonimizar",
        system_prompt="VocÃª Ã© um assistente jurÃ­dico que identifica dados pessoais em documentos.",
        privacy_level="detection_only"
    )
    
    print(f"âœ… Agente criado: {detection_agent.name}")
    print(f"   ğŸ”§ Modo: {detection_agent.privacy_level}")
    print(f"   ğŸ” DetecÃ§Ã£o apenas: {detection_agent.detection_only}")
    print(f"   ğŸ”’ Auto-anonimizaÃ§Ã£o: {detection_agent.auto_anonymize}")
    
    # Documento de contrato
    contract_content = """
    CONTRATO DE PRESTAÃ‡ÃƒO DE SERVIÃ‡OS ADVOCATÃCIOS
    
    CONTRATANTE:
    Nome: JoÃ£o Carlos da Silva
    CPF: 987.654.321-00
    RG: 98.765.432-1
    E-mail: joao.carlos@empresa.com.br
    Telefone: (21) 99888-7766
    
    CONTRATADO:
    EscritÃ³rio de Advocacia Silva & Associados
    CNPJ: 98.765.432/0001-10
    ResponsÃ¡vel: Dr. Pedro Silva (OAB/SP 123456)
    
    Objeto: PrestaÃ§Ã£o de serviÃ§os jurÃ­dicos especializados...
    """
    
    # Teste de processamento de documento
    print(f"\nğŸ“„ Processando documento com agente de detecÃ§Ã£o:")
    doc_result = detection_agent.detect_document_data_only(
        content=contract_content,
        filename="contrato_servicos.txt"
    )
    
    if doc_result['success']:
        print(f"   âœ… Documento processado com sucesso")
        print(f"   ğŸ“ Arquivo: {doc_result['filename']}")
        print(f"   ğŸ” ConteÃºdo original preservado: {doc_result['original_content_preserved']}")
        
        detection = doc_result['detection_result']
        print(f"   ğŸ“Š Dados detectados: {detection['detected_types']}")
        print(f"   ğŸ”¢ Total de ocorrÃªncias: {detection['total_occurrences']}")
        print(f"   ğŸ“‚ Categoria: {detection['data_category']}")
    else:
        print(f"   âŒ Falha: {doc_result.get('error')}")
    
    # Teste de query
    print(f"\nâ“ Testando query com dados pessoais:")
    query = "Analise o contrato do JoÃ£o Carlos (CPF 987.654.321-00) e identifique as clÃ¡usulas principais."
    
    query_result = detection_agent.query_with_detection_only(query)
    
    if query_result['success']:
        print(f"   âœ… Query processada")
        print(f"   ğŸ” Query original preservada: {query_result['privacy_info']['original_query_preserved']}")
        print(f"   ğŸ“Š Dados detectados na query: {query_result['query_detection']['detected_types']}")
        print(f"   ğŸ’¬ Resposta (primeiros 100 chars): {query_result['response'][:100]}...")
    else:
        print(f"   âŒ Falha: {query_result.get('error')}")
    
    return detection_agent

def test_risk_analysis_scenarios():
    """Testa anÃ¡lise de riscos em diferentes cenÃ¡rios"""
    print("\nğŸ“Š Testando anÃ¡lise de riscos em diferentes cenÃ¡rios...")
    
    scenarios = {
        "Documento Seguro": "Este Ã© um documento pÃºblico sobre polÃ­ticas da empresa, sem dados pessoais.",
        
        "Baixo Risco": """
        Lista de participantes do evento:
        - JoÃ£o (joao@email.com)
        - Maria (maria@email.com)
        """,
        
        "MÃ©dio Risco": """
        Cadastro de cliente:
        Nome: Ana Silva
        E-mail: ana@email.com
        Telefone: (11) 99999-8888
        CEP: 01234-567
        """,
        
        "Alto Risco": """
        Ficha mÃ©dica:
        Paciente: Carlos Santos
        CPF: 111.222.333-44
        RG: 11.222.333-4
        Telefone: (11) 88888-7777
        DiagnÃ³stico: Diabetes tipo 2
        """,
        
        "CrÃ­tico": """
        Base de dados completa:
        1. Maria Silva - CPF: 123.456.789-10 - RG: 12.345.678-9 - Tel: (11) 99999-8888
        2. JoÃ£o Santos - CPF: 987.654.321-00 - RG: 98.765.432-1 - Tel: (21) 88888-7777
        3. Ana Costa - CPF: 555.666.777-88 - RG: 55.666.777-8 - Tel: (31) 77777-6666
        CNPJ Empresa: 12.345.678/0001-90
        """
    }
    
    for scenario_name, content in scenarios.items():
        print(f"\n   ğŸ“‹ CenÃ¡rio: {scenario_name}")
        
        risk = privacy_manager.analyze_document_privacy_risks(content)
        
        print(f"      ğŸ¯ Risco: {risk['risk_level']} (Score: {risk['risk_score']})")
        print(f"      ğŸ“ {risk['risk_description']}")
        print(f"      ğŸ“Š Tipos detectados: {risk['detection_summary']['detected_types']}")
        
        if risk['recommendations']:
            print(f"      ğŸ’¡ Primeira recomendaÃ§Ã£o: {risk['recommendations'][0]}")

def test_comparison_modes():
    """Compara diferentes modos de privacidade"""
    print("\nğŸ”„ Comparando modos de privacidade...")
    
    test_content = """
    RelatÃ³rio de anÃ¡lise:
    Cliente: Pedro Silva (CPF: 999.888.777-66)
    E-mail: pedro@empresa.com
    Telefone: (11) 95555-4444
    """
    
    # Cria agentes com diferentes modos
    agents = {
        "Standard": privacy_agent_system.create_privacy_agent(
            name="Agente Standard", description="Modo padrÃ£o",
            system_prompt="Assistente padrÃ£o", privacy_level="standard"
        ),
        "High Privacy": privacy_agent_system.create_privacy_agent(
            name="Agente High", description="Alta privacidade",
            system_prompt="Assistente alta privacidade", privacy_level="high"
        ),
        "Detection Only": privacy_agent_system.create_privacy_agent(
            name="Agente Detection", description="Apenas detecÃ§Ã£o",
            system_prompt="Assistente detecÃ§Ã£o", privacy_level="detection_only"
        )
    }
    
    print(f"\nğŸ“Š ComparaÃ§Ã£o de processamento:")
    
    for mode_name, agent in agents.items():
        print(f"\n   ğŸ¤– {mode_name}:")
        print(f"      ğŸ”§ AnonimizaÃ§Ã£o automÃ¡tica: {agent.auto_anonymize}")
        print(f"      ğŸ” Apenas detecÃ§Ã£o: {agent.detection_only}")
        print(f"      âš–ï¸  Requer consentimento: {agent.require_consent}")
        
        if agent.detection_only:
            # Usa mÃ©todo especÃ­fico para detecÃ§Ã£o
            result = agent.detect_document_data_only(test_content, "test.txt")
            if result['success']:
                print(f"      âœ… ConteÃºdo original preservado: {result['original_content_preserved']}")
                print(f"      ğŸ“Š Dados detectados: {result['detection_result']['detected_types']}")
        else:
            # Usa mÃ©todo normal (pode anonimizar)
            result = agent.process_document_with_privacy(
                test_content, "test.txt", user_consent=True
            )
            if result['success']:
                print(f"      ğŸ”’ AnonimizaÃ§Ã£o aplicada: {result['privacy_info']['anonymization_applied']}")
                print(f"      ğŸ“Š Dados detectados: {list(result['privacy_info']['detected_data'].keys())}")

def main():
    """FunÃ§Ã£o principal de teste"""
    print("ğŸ” Iniciando testes do modo DetecÃ§Ã£o Apenas")
    print("=" * 60)
    print("ğŸ¯ Objetivo: Detectar dados pessoais SEM anonimizar")
    print("=" * 60)
    
    try:
        # Teste 1: Funcionalidades bÃ¡sicas
        detection_result, risk_analysis = test_detection_only_functionality()
        
        # Teste 2: Agente especÃ­fico
        detection_agent = test_detection_only_agent()
        
        # Teste 3: CenÃ¡rios de risco
        test_risk_analysis_scenarios()
        
        # Teste 4: ComparaÃ§Ã£o de modos
        test_comparison_modes()
        
        print("\n" + "=" * 60)
        print("âœ… TODOS OS TESTES DE DETECÃ‡ÃƒO CONCLUÃDOS!")
        print("ğŸ¯ Funcionalidades validadas:")
        print("   ğŸ” DetecÃ§Ã£o sem anonimizaÃ§Ã£o")
        print("   ğŸ“Š AnÃ¡lise de riscos de privacidade")
        print("   ğŸ¤– Agentes em modo detection_only")
        print("   ğŸ“‹ PreservaÃ§Ã£o do conteÃºdo original")
        print("   âš–ï¸  Compliance LGPD com transparÃªncia")
        
        # RelatÃ³rio final
        print(f"\nğŸ“‹ Resumo dos agentes criados:")
        system_report = privacy_agent_system.get_system_privacy_report()
        detection_agents = [
            agent for agent in privacy_agent_system.agents.values()
            if isinstance(agent, PrivacyAwareAgent) and agent.detection_only
        ]
        
        print(f"   ğŸ” Agentes detection_only: {len(detection_agents)}")
        print(f"   ğŸ“ Total de registros: {system_report['compliance_summary']['total_data_records']}")
        
    except Exception as e:
        print(f"\nâŒ ERRO durante os testes: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 