"""
üöÄ RAG PYTHON v1.5.1 - SISTEMA COMPLETO UNIFICADO
Sistema RAG com Multi-LLM, Agentes, Privacidade LGPD e Dashboard
Todas as funcionalidades em uma √∫nica interface
"""

import streamlit as st
import os
import tempfile
import json
import uuid
from pathlib import Path
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import psycopg2
import psycopg2.extras
import time

# Importa√ß√µes do sistema
from llm_providers import LLMProviderManager
from privacy_system import privacy_manager
from vector_store import VectorStore
from database import Database

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="üöÄ RAG Python v1.5.1 - Sistema Completo",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .feature-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
        border-left: 4px solid #1f77b4;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        border-left: 4px solid #1f77b4;
    }
    .user-message {
        background-color: #e3f2fd;
        border-left-color: #2196f3;
    }
    .assistant-message {
        background-color: #f3e5f5;
        border-left-color: #9c27b0;
    }
    .provider-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 0.5rem;
    }
    .agent-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 0.5rem;
    }
    .privacy-alert {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
        color: #155724;
    }
    .info-box {
        background-color: #e8f5e8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #4caf50;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding-left: 20px;
        padding-right: 20px;
        background-color: #f0f2f6;
        border-radius: 10px 10px 0px 0px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #1f77b4;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

class AgentManager:
    """Gerenciador de Agentes com funcionalidades completas"""
    
    def __init__(self):
        self.llm_manager = LLMProviderManager()
    
    @staticmethod
    def _execute_query(query: str, params: tuple = (), fetch: Optional[str] = None):
        """Executa query no banco de dados"""
        conn = None
        try:
            conn = Database.get_connection()
            with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:
                cur.execute(query, params)
                if fetch == 'one':
                    result = cur.fetchone()
                elif fetch == 'all':
                    result = cur.fetchall()
                else:
                    result = None
                conn.commit()
                return result
        except Exception as e:
            logger.error(f"Database query failed: {e}")
            if conn: conn.rollback()
            return None
        finally:
            if conn: Database.release_connection(conn)
    
    def create_agent(self, name: str, description: str, agent_type: str, system_prompt: str, 
                    model: str = "gpt-3.5-turbo", temperature: float = 0.7) -> Optional[str]:
        """Cria um novo agente"""
        try:
            query = """
                INSERT INTO agentes (name, description, system_prompt, model, temperature, agent_type) 
                VALUES (%s, %s, %s, %s, %s, %s) RETURNING id;
            """
            params = (name, description, system_prompt, model, temperature, agent_type)
            result = self._execute_query(query, params, fetch='one')
            return str(result['id']) if result else None
        except Exception as e:
            logger.error(f"Erro ao criar agente: {e}")
            return None
    
    def get_all_agents(self) -> List[Dict]:
        """Obt√©m todos os agentes"""
        try:
            query = "SELECT * FROM agentes ORDER BY created_at DESC"
            rows = self._execute_query(query, fetch='all')
            return [dict(row) for row in rows] if rows else []
        except Exception as e:
            logger.error(f"Erro ao buscar agentes: {e}")
            return []
    
    def get_agent_by_id(self, agent_id: str) -> Optional[Dict]:
        """Obt√©m agente por ID"""
        try:
            query = "SELECT * FROM agentes WHERE id = %s"
            row = self._execute_query(query, (agent_id,), fetch='one')
            return dict(row) if row else None
        except Exception as e:
            logger.error(f"Erro ao buscar agente: {e}")
            return None
    
    def update_agent(self, agent_id: str, data: Dict) -> bool:
        """Atualiza um agente"""
        try:
            query = """
                UPDATE agentes SET name = %s, description = %s, system_prompt = %s, 
                model = %s, temperature = %s WHERE id = %s
            """
            params = (data['name'], data['description'], data['system_prompt'], 
                     data['model'], data['temperature'], agent_id)
            self._execute_query(query, params)
            return True
        except Exception as e:
            logger.error(f"Erro ao atualizar agente: {e}")
            return False
    
    def delete_agent(self, agent_id: str) -> bool:
        """Deleta um agente"""
        try:
            query = "DELETE FROM agentes WHERE id = %s"
            self._execute_query(query, (agent_id,))
            return True
        except Exception as e:
            logger.error(f"Erro ao deletar agente: {e}")
            return False

class RAGSystemUnified:
    """Sistema RAG unificado com todas as funcionalidades"""
    
    def __init__(self):
        self.llm_manager = LLMProviderManager()
        self.agent_manager = AgentManager()
        self.documents = []
        self.knowledge_base = {}
        self.settings = {
            'model_name': 'gpt-3.5-turbo',
            'temperature': 0.7,
            'max_tokens': 1000
        }
    
    def query_with_agent(self, question: str, agent_id: str = None) -> Dict:
        """Processa pergunta com agente espec√≠fico"""
        try:
            agent = None
            if agent_id:
                agent = self.agent_manager.get_agent_by_id(agent_id)
            
            # Preparar mensagens
            messages = []
            
            if agent:
                messages.append({
                    "role": "system", 
                    "content": agent['system_prompt']
                })
            
            messages.append({"role": "user", "content": question})
            
            # Gerar resposta
            model = agent['model'] if agent else self.settings['model_name']
            temperature = agent['temperature'] if agent else self.settings['temperature']
            
            response = self.llm_manager.generate_response(
                messages,
                model=model,
                temperature=temperature
            )
            
            return {
                'answer': response,
                'agent_used': agent['name'] if agent else 'Sistema Padr√£o',
                'model_used': model,
                'success': True
            }
            
        except Exception as e:
            logger.error(f"Erro ao processar pergunta: {e}")
            return {
                'answer': f"Erro: {str(e)}",
                'agent_used': 'Erro',
                'model_used': 'N/A',
                'success': False
            }
    
    def multi_llm_compare(self, question: str, providers: List[str] = None) -> Dict:
        """Compara respostas de m√∫ltiplos LLMs"""
        try:
            if not providers:
                providers = ['openai', 'google', 'openrouter', 'deepseek']
            
            messages = [{"role": "user", "content": question}]
            
            results = self.llm_manager.compare_multi_llm(
                messages, 
                providers=providers,
                model=self.settings['model_name'],
                temperature=self.settings['temperature']
            )
            
            return results
            
        except Exception as e:
            logger.error(f"Erro na compara√ß√£o Multi-LLM: {e}")
            return {'error': str(e)}

@st.cache_resource
def initialize_system():
    """Inicializa o sistema unificado"""
    return RAGSystemUnified()

def main():
    """Interface principal do sistema"""
    
    # Inicializar sistema
    rag_system = initialize_system()
    
    # Header principal
    st.markdown('<h1 class="main-header">üöÄ RAG Python v1.5.1 - Sistema Completo</h1>', 
                unsafe_allow_html=True)
    
    # Tabs principais
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "üè† Dashboard",
        "üí¨ Chat RAG", 
        "ü§ñ Agentes",
        "üîÑ Multi-LLM",
        "üîí Privacidade",
        "üìÅ Documentos",
        "‚öôÔ∏è Configura√ß√µes"
    ])
    
    with tab1:
        dashboard_interface(rag_system)
    
    with tab2:
        chat_rag_interface(rag_system)
    
    with tab3:
        agents_interface(rag_system)
    
    with tab4:
        multi_llm_interface(rag_system)
    
    with tab5:
        privacy_interface(rag_system)
    
    with tab6:
        documents_interface(rag_system)
    
    with tab7:
        settings_interface(rag_system)

def dashboard_interface(rag_system):
    """Interface do Dashboard"""
    st.header("üìä Dashboard do Sistema")
    
    # M√©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        try:
            agents = rag_system.agent_manager.get_all_agents()
            st.metric("ü§ñ Agentes", len(agents), help="Agentes especializados cadastrados")
        except:
            st.metric("ü§ñ Agentes", "N/A", help="Erro ao carregar agentes")
    
    with col2:
        st.metric("üìÑ Documentos", len(rag_system.documents), help="Documentos na base de conhecimento")
    
    with col3:
        configured_keys = sum([
            bool(os.getenv('OPENAI_API_KEY')),
            bool(os.getenv('GOOGLE_API_KEY')),
            bool(os.getenv('OPENROUTER_API_KEY')),
            bool(os.getenv('DEEPSEEK_API_KEY'))
        ])
        st.metric("üîë API Keys", f"{configured_keys}/4", help="API Keys configuradas")
    
    with col4:
        try:
            providers_info = rag_system.llm_manager.get_provider_info()
            active_providers = 0
            for info in providers_info.values():
                if isinstance(info, dict) and info.get('available', False):
                    active_providers += 1
            st.metric("üåê Provedores", f"{active_providers}/4", help="Provedores LLM ativos")
        except:
            st.metric("üåê Provedores", "N/A", help="Erro ao verificar provedores")
    
    # Status dos provedores LLM
    st.markdown("---")
    st.subheader("üåê Status dos Provedores LLM")
    
    # Verificar status das API keys
    providers_status = {
        "OpenAI": {
            "key": bool(os.getenv('OPENAI_API_KEY')),
            "icon": "ü§ñ",
            "models": ["gpt-3.5-turbo", "gpt-4", "gpt-4o-mini"]
        },
        "Google Gemini": {
            "key": bool(os.getenv('GOOGLE_API_KEY')),
            "icon": "üß†",
            "models": ["gemini-pro", "gemini-1.5-flash"]
        },
        "OpenRouter": {
            "key": bool(os.getenv('OPENROUTER_API_KEY')),
            "icon": "üåê",
            "models": ["claude-3", "llama-2", "mixtral"]
        },
        "DeepSeek": {
            "key": bool(os.getenv('DEEPSEEK_API_KEY')),
            "icon": "üîÆ",
            "models": ["deepseek-chat", "deepseek-coder"]
        }
    }
    
    cols = st.columns(4)
    for i, (provider, info) in enumerate(providers_status.items()):
        with cols[i]:
            status = "‚úÖ Ativo" if info['key'] else "‚ùå Inativo"
            color = "#d4edda" if info['key'] else "#f8d7da"
            border_color = "#28a745" if info['key'] else "#dc3545"
            
            st.markdown(f"""
            <div style="
                background-color: {color}; 
                border: 2px solid {border_color}; 
                border-radius: 10px; 
                padding: 15px; 
                text-align: center;
                margin: 5px;
                min-height: 120px;
            ">
                <h3 style="margin: 0;">{info['icon']} {provider}</h3>
                <p style="margin: 5px 0; font-weight: bold;">{status}</p>
                <small>Modelos: {len(info['models'])}</small>
            </div>
            """, unsafe_allow_html=True)
    
    # Funcionalidades do sistema
    st.markdown("---")
    st.subheader("üöÄ Funcionalidades Dispon√≠veis")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### üí¨ Chat RAG
        - Conversa√ß√£o inteligente com agentes
        - Busca em base de conhecimento
        - Hist√≥rico de conversas
        
        ### ü§ñ Sistema de Agentes
        - Agentes especializados por dom√≠nio
        - Configura√ß√£o personalizada
        - Prompts otimizados
        """)
    
    with col2:
        st.markdown("""
        ### üîÑ Multi-LLM
        - Compara√ß√£o entre 4 provedores
        - M√©tricas de performance
        - An√°lise de qualidade
        
        ### üîí Privacidade LGPD
        - Detec√ß√£o de dados sens√≠veis
        - Anonimiza√ß√£o autom√°tica
        - Compliance reports
        """)
    
    # A√ß√µes r√°pidas
    st.markdown("---")
    st.subheader("‚ö° A√ß√µes R√°pidas")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("üîß Configurar APIs", help="Ir para configura√ß√µes de API"):
            st.switch_page("‚öôÔ∏è Configura√ß√µes")
    
    with col2:
        if st.button("ü§ñ Criar Agente", help="Criar novo agente"):
            st.switch_page("ü§ñ Agentes")
    
    with col3:
        if st.button("üì§ Upload Docs", help="Fazer upload de documentos"):
            st.switch_page("üìÅ Documentos")
    
    with col4:
        if st.button("üß™ Testar LLMs", help="Testar conectividade"):
            st.switch_page("‚öôÔ∏è Configura√ß√µes")
    
    # Informa√ß√µes do sistema
    st.markdown("---")
    st.subheader("‚ÑπÔ∏è Informa√ß√µes do Sistema")
    
    info_col1, info_col2 = st.columns(2)
    
    with info_col1:
        st.info("""
        **üöÄ RAG Python v1.5.1-Unified**
        
        Sistema completo de RAG com:
        - Multi-LLM integration
        - Sistema de agentes especializados
        - Compliance LGPD
        - Interface unificada
        """)
    
    with info_col2:
        st.success("""
        **‚úÖ Sistema Operacional**
        
        Status:
        - ‚úÖ Interface carregada
        - ‚úÖ Banco PostgreSQL conectado
        - ‚úÖ Sistema de arquivos OK
        - ‚úÖ Pronto para uso
        """)

def chat_rag_interface(rag_system):
    """Interface do Chat RAG"""
    st.header("üí¨ Chat RAG Inteligente")
    
    # Sele√ß√£o de agente
    agents = rag_system.agent_manager.get_all_agents()
    agent_options = {"Sistema Padr√£o": None}
    agent_options.update({agent['name']: agent['id'] for agent in agents})
    
    selected_agent = st.selectbox("ü§ñ Selecionar Agente:", list(agent_options.keys()))
    agent_id = agent_options[selected_agent]
    
    # Hist√≥rico do chat
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # √Årea de mensagens
    chat_container = st.container()
    
    with chat_container:
        for message in st.session_state.chat_history:
            if message['role'] == 'user':
                st.markdown(f"""
                <div class="chat-message user-message">
                    <strong>üë§ Voc√™:</strong><br>
                    {message['content']}
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="chat-message assistant-message">
                    <strong>ü§ñ {message.get('agent', 'Assistente')}:</strong><br>
                    {message['content']}
                    <div style="font-size: 0.8em; color: #666; margin-top: 0.5rem;">
                        Modelo: {message.get('model', 'N/A')}
                    </div>
                </div>
                """, unsafe_allow_html=True)
    
    # Input de mensagem
    user_input = st.text_input("üí≠ Digite sua pergunta:", key="chat_input", 
                              placeholder="Fa√ßa uma pergunta...")
    
    col1, col2 = st.columns([1, 4])
    
    with col1:
        if st.button("üì§ Enviar", type="primary"):
            if user_input:
                # Adicionar mensagem do usu√°rio
                st.session_state.chat_history.append({
                    'role': 'user',
                    'content': user_input
                })
                
                # Processar resposta
                with st.spinner("ü§î Pensando..."):
                    result = rag_system.query_with_agent(user_input, agent_id)
                
                # Adicionar resposta do assistente
                st.session_state.chat_history.append({
                    'role': 'assistant',
                    'content': result['answer'],
                    'agent': result['agent_used'],
                    'model': result['model_used']
                })
                
                st.rerun()
    
    with col2:
        if st.button("üóëÔ∏è Limpar Chat"):
            st.session_state.chat_history = []
            st.rerun()

def agents_interface(rag_system):
    """Interface de gerenciamento de agentes"""
    st.header("ü§ñ Sistema de Agentes Especializados")
    
    tab1, tab2, tab3 = st.tabs(["üìã Lista de Agentes", "‚ûï Criar Agente", "‚öôÔ∏è Configurar Agente"])
    
    with tab1:
        st.subheader("üë• Agentes Cadastrados")
        
        agents = rag_system.agent_manager.get_all_agents()
        
        if agents:
            for agent in agents:
                with st.expander(f"ü§ñ {agent['name']} - {agent.get('agent_type', 'Geral')}"):
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.write(f"**Descri√ß√£o:** {agent['description']}")
                        st.write(f"**Modelo:** {agent['model']}")
                        st.write(f"**Temperatura:** {agent['temperature']}")
                        st.write(f"**Criado em:** {agent.get('created_at', 'N/A')}")
                        
                        with st.expander("Ver Prompt do Sistema"):
                            st.code(agent['system_prompt'], language='text')
                    
                    with col2:
                        if st.button("üóëÔ∏è Deletar", key=f"delete_{agent['id']}"):
                            if rag_system.agent_manager.delete_agent(agent['id']):
                                st.success("Agente deletado com sucesso!")
                                st.rerun()
        else:
            st.info("üìù Nenhum agente cadastrado ainda. Crie seu primeiro agente!")
    
    with tab2:
        st.subheader("‚ûï Criar Novo Agente")
        
        with st.form("create_agent_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                agent_name = st.text_input("üè∑Ô∏è Nome do Agente", placeholder="Ex: Assistente Jur√≠dico")
                agent_type = st.selectbox("üéØ Tipo de Agente", [
                    "Conversacional", "Pesquisador", "Executor", "Especialista"
                ])
                model = st.selectbox("ü§ñ Modelo LLM", [
                    "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview", "gpt-4o-mini",
                    "gemini-pro", "gemini-pro-vision", "deepseek-chat", "deepseek-coder"
                ])
            
            with col2:
                temperature = st.slider("üå°Ô∏è Temperatura", 0.0, 2.0, 0.7, 0.1)
                description = st.text_area("üìù Descri√ß√£o", 
                                         placeholder="Descreva o prop√≥sito e especialidade do agente")
            
            system_prompt = st.text_area("üé≠ Prompt do Sistema", height=200,
                                       placeholder="Defina o comportamento e especialidade do agente...")
            
            if st.form_submit_button("üöÄ Criar Agente", type="primary"):
                if agent_name and system_prompt:
                    agent_id = rag_system.agent_manager.create_agent(
                        name=agent_name,
                        description=description,
                        agent_type=agent_type,
                        system_prompt=system_prompt,
                        model=model,
                        temperature=temperature
                    )
                    
                    if agent_id:
                        st.success(f"‚úÖ Agente '{agent_name}' criado com sucesso!")
                        st.balloons()
                        st.rerun()
                    else:
                        st.error("‚ùå Erro ao criar agente. Verifique a conex√£o com banco de dados.")
                else:
                    st.error("‚ö†Ô∏è Preencha pelo menos o nome e o prompt do sistema.")
    
    with tab3:
        st.subheader("‚öôÔ∏è Configurar Agente Existente")
        
        agents = rag_system.agent_manager.get_all_agents()
        if agents:
            agent_to_edit = st.selectbox("Selecionar Agente:", 
                                       [f"{a['name']} (ID: {a['id']})" for a in agents])
            
            if agent_to_edit:
                agent_id = agent_to_edit.split("ID: ")[1].rstrip(")")
                agent = rag_system.agent_manager.get_agent_by_id(agent_id)
                
                if agent:
                    with st.form("edit_agent_form"):
                        new_name = st.text_input("Nome", value=agent['name'])
                        new_description = st.text_area("Descri√ß√£o", value=agent['description'])
                        new_model = st.selectbox("Modelo", [
                            "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview", "gpt-4o-mini",
                            "gemini-pro", "deepseek-chat"
                        ], index=0 if agent['model'] == "gpt-3.5-turbo" else 0)
                        new_temperature = st.slider("Temperatura", 0.0, 2.0, float(agent['temperature']), 0.1)
                        new_prompt = st.text_area("Prompt do Sistema", value=agent['system_prompt'], height=200)
                        
                        if st.form_submit_button("üíæ Salvar Altera√ß√µes"):
                            update_data = {
                                'name': new_name,
                                'description': new_description,
                                'system_prompt': new_prompt,
                                'model': new_model,
                                'temperature': new_temperature
                            }
                            
                            if rag_system.agent_manager.update_agent(agent_id, update_data):
                                st.success("‚úÖ Agente atualizado com sucesso!")
                                st.rerun()
                            else:
                                st.error("‚ùå Erro ao atualizar agente.")
        else:
            st.info("Nenhum agente dispon√≠vel para configura√ß√£o.")

def multi_llm_interface(rag_system):
    """Interface de compara√ß√£o Multi-LLM"""
    st.header("üîÑ Comparador Multi-LLM")
    
    st.write("Compare respostas de diferentes provedores de IA lado a lado")
    
    # Sele√ß√£o de provedores
    st.subheader("üéØ Selecionar Provedores para Compara√ß√£o")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        use_openai = st.checkbox("ü§ñ OpenAI", value=True)
    with col2:
        use_google = st.checkbox("üß† Google Gemini", value=True)
    with col3:
        use_openrouter = st.checkbox("üåê OpenRouter", value=True)
    with col4:
        use_deepseek = st.checkbox("üîÆ DeepSeek", value=True)
    
    # Pergunta para compara√ß√£o
    question = st.text_area("‚ùì Pergunta para Compara√ß√£o:", 
                           placeholder="Digite sua pergunta aqui...", height=100)
    
    if st.button("üöÄ Comparar Respostas", type="primary"):
        if question:
            providers = []
            if use_openai: providers.append('openai')
            if use_google: providers.append('google')
            if use_openrouter: providers.append('openrouter')
            if use_deepseek: providers.append('deepseek')
            
            if providers:
                with st.spinner("üîÑ Processando compara√ß√£o..."):
                    results = rag_system.multi_llm_compare(question, providers)
                
                if 'error' not in results:
                    st.subheader("üìä Resultados da Compara√ß√£o")
                    
                    # Criar colunas para cada provedor
                    cols = st.columns(len(providers))
                    
                    for i, provider in enumerate(providers):
                        with cols[i]:
                            if provider in results:
                                result = results[provider]
                                
                                # Card do provedor
                                st.markdown(f"""
                                <div class="provider-card">
                                    <h4>{provider.upper()}</h4>
                                    <p>‚è±Ô∏è Tempo: {result.get('response_time', 'N/A')}s</p>
                                    <p>üéØ Status: {'‚úÖ' if result.get('success') else '‚ùå'}</p>
                                </div>
                                """, unsafe_allow_html=True)
                                
                                # Resposta
                                if result.get('success'):
                                    st.text_area(f"Resposta {provider.upper()}:", 
                                               value=result.get('response', 'Erro na resposta'),
                                               height=200, key=f"response_{provider}")
                                else:
                                    st.error(f"Erro: {result.get('error', 'Erro desconhecido')}")
                    
                    # M√©tricas de compara√ß√£o
                    st.subheader("üìà M√©tricas de Performance")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        times = [results[p].get('response_time', 0) for p in providers if p in results]
                        if times:
                            fastest = min(times)
                            fastest_provider = [p for p in providers if p in results and results[p].get('response_time') == fastest][0]
                            st.metric("‚ö° Mais R√°pido", fastest_provider.upper(), f"{fastest:.2f}s")
                    
                    with col2:
                        successful = sum(1 for p in providers if p in results and results[p].get('success'))
                        st.metric("‚úÖ Sucessos", f"{successful}/{len(providers)}")
                    
                    with col3:
                        avg_time = sum(times) / len(times) if times else 0
                        st.metric("‚è±Ô∏è Tempo M√©dio", f"{avg_time:.2f}s")
                
                else:
                    st.error(f"Erro na compara√ß√£o: {results['error']}")
            else:
                st.warning("‚ö†Ô∏è Selecione pelo menos um provedor para compara√ß√£o.")
        else:
            st.warning("‚ö†Ô∏è Digite uma pergunta para compara√ß√£o.")

def privacy_interface(rag_system):
    """Interface de privacidade LGPD"""
    st.header("üîí Sistema de Privacidade LGPD")
    
    tab1, tab2, tab3 = st.tabs(["üîç Detec√ß√£o", "üìä An√°lise", "üìã Relat√≥rios"])
    
    with tab1:
        st.subheader("üîç Detec√ß√£o de Dados Pessoais")
        
        text_to_analyze = st.text_area("üìù Texto para An√°lise:", 
                                      placeholder="Cole o texto que deseja analisar...", 
                                      height=200)
        
        if st.button("üîç Analisar Dados Pessoais"):
            if text_to_analyze:
                with st.spinner("üîç Analisando dados pessoais..."):
                    try:
                        results = privacy_manager.detect_personal_data(text_to_analyze)
                        
                        if results.get('entities'):
                            st.subheader("‚ö†Ô∏è Dados Pessoais Detectados")
                            
                            for entity in results['entities']:
                                st.markdown(f"""
                                <div class="privacy-alert">
                                    <strong>Tipo:</strong> {entity.get('entity_type', 'N/A')}<br>
                                    <strong>Texto:</strong> {entity.get('text', 'N/A')}<br>
                                    <strong>Confian√ßa:</strong> {entity.get('confidence', 0):.2%}<br>
                                    <strong>Posi√ß√£o:</strong> {entity.get('start', 0)}-{entity.get('end', 0)}
                                </div>
                                """, unsafe_allow_html=True)
                        else:
                            st.success("‚úÖ Nenhum dado pessoal detectado!")
                    
                    except Exception as e:
                        st.error(f"Erro na an√°lise: {str(e)}")
            else:
                st.warning("‚ö†Ô∏è Digite um texto para an√°lise.")
    
    with tab2:
        st.subheader("üìä An√°lise de Riscos LGPD")
        
        st.info("üõ°Ô∏è Sistema de an√°lise de riscos em desenvolvimento...")
        
        # Placeholder para an√°lise de riscos
        risk_level = st.select_slider("üéöÔ∏è N√≠vel de Risco Simulado:", 
                                     options=["Baixo", "M√©dio", "Alto", "Cr√≠tico"],
                                     value="M√©dio")
        
        if risk_level == "Baixo":
            st.success("‚úÖ Risco Baixo: Conformidade adequada")
        elif risk_level == "M√©dio":
            st.warning("‚ö†Ô∏è Risco M√©dio: Aten√ß√£o necess√°ria")
        elif risk_level == "Alto":
            st.error("üö® Risco Alto: A√ß√£o imediata requerida")
        else:
            st.error("üî• Risco Cr√≠tico: Viola√ß√£o grave detectada")
    
    with tab3:
        st.subheader("üìã Relat√≥rios de Compliance")
        
        if st.button("üìä Gerar Relat√≥rio"):
            st.markdown("""
            <div class="success-box">
                <h4>üìÑ Relat√≥rio de Compliance LGPD</h4>
                <p><strong>Data:</strong> {}</p>
                <p><strong>Status Geral:</strong> ‚úÖ Conforme</p>
                <p><strong>Dados Processados:</strong> 0 registros</p>
                <p><strong>Viola√ß√µes Detectadas:</strong> 0</p>
                <p><strong>Recomenda√ß√µes:</strong> Sistema operando dentro dos par√¢metros LGPD</p>
            </div>
            """.format(datetime.now().strftime("%d/%m/%Y %H:%M")), unsafe_allow_html=True)

def documents_interface(rag_system):
    """Interface de gerenciamento de documentos"""
    st.header("üìÅ Gerenciamento de Documentos")
    
    tab1, tab2, tab3 = st.tabs(["üì§ Upload", "üìã Lista", "üîç Busca"])
    
    with tab1:
        st.subheader("üì§ Upload de Documentos")
        
        uploaded_files = st.file_uploader("Selecionar Arquivos:", 
                                        accept_multiple_files=True,
                                        type=['txt', 'pdf', 'docx', 'md'])
        
        if uploaded_files:
            for file in uploaded_files:
                st.write(f"üìÑ {file.name} ({file.size} bytes)")
        
        if st.button("üì§ Processar Uploads"):
            if uploaded_files:
                with st.spinner("üì§ Processando arquivos..."):
                    for file in uploaded_files:
                        # Simular processamento
                        content = file.read().decode('utf-8') if file.type == 'text/plain' else "Conte√∫do processado"
                        
                        rag_system.documents.append({
                            'name': file.name,
                            'content': content,
                            'type': file.type,
                            'size': file.size,
                            'uploaded_at': datetime.now().isoformat()
                        })
                
                st.success(f"‚úÖ {len(uploaded_files)} arquivo(s) processado(s) com sucesso!")
                st.rerun()
            else:
                st.warning("‚ö†Ô∏è Selecione arquivos para upload.")
    
    with tab2:
        st.subheader("üìã Documentos Carregados")
        
        if rag_system.documents:
            for i, doc in enumerate(rag_system.documents):
                with st.expander(f"üìÑ {doc['name']}"):
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.write(f"**Tipo:** {doc.get('type', 'N/A')}")
                        st.write(f"**Tamanho:** {doc.get('size', 0)} bytes")
                        st.write(f"**Upload:** {doc.get('uploaded_at', 'N/A')}")
                        
                        if st.button(f"üëÅÔ∏è Visualizar", key=f"view_{i}"):
                            st.text_area("Conte√∫do:", doc.get('content', '')[:500] + "...", height=100)
                    
                    with col2:
                        if st.button(f"üóëÔ∏è Remover", key=f"remove_{i}"):
                            rag_system.documents.pop(i)
                            st.rerun()
        else:
            st.info("üìù Nenhum documento carregado ainda.")
    
    with tab3:
        st.subheader("üîç Busca em Documentos")
        
        search_query = st.text_input("üîç Termo de Busca:", placeholder="Digite para buscar...")
        
        if search_query:
            results = []
            for doc in rag_system.documents:
                if search_query.lower() in doc.get('content', '').lower():
                    results.append(doc)
            
            if results:
                st.write(f"üìä Encontrados {len(results)} resultado(s):")
                for doc in results:
                    st.write(f"üìÑ **{doc['name']}**")
            else:
                st.info("üîç Nenhum resultado encontrado.")

def settings_interface(rag_system):
    """Interface de configura√ß√µes"""
    st.header("‚öôÔ∏è Configura√ß√µes do Sistema")
    
    tab1, tab2, tab3, tab4 = st.tabs(["üîë API Keys", "üß™ Testes", "üéõÔ∏è Geral", "üíæ Backup"])
    
    with tab1:
        st.subheader("üîë Configura√ß√£o de Provedores LLM")
        
        # Configura√ß√£o das API Keys
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ü§ñ OpenAI")
            openai_key = st.text_input("OpenAI API Key:", type="password", 
                                      value=os.getenv('OPENAI_API_KEY', ''),
                                      key="openai_key")
            if openai_key:
                os.environ['OPENAI_API_KEY'] = openai_key
            
            st.markdown("### üåê OpenRouter")
            openrouter_key = st.text_input("OpenRouter API Key:", type="password",
                                          value=os.getenv('OPENROUTER_API_KEY', ''),
                                          key="openrouter_key")
            if openrouter_key:
                os.environ['OPENROUTER_API_KEY'] = openrouter_key
        
        with col2:
            st.markdown("### üß† Google Gemini")
            google_key = st.text_input("Google Gemini API Key:", type="password",
                                      value=os.getenv('GOOGLE_API_KEY', ''),
                                      key="google_key")
            if google_key:
                os.environ['GOOGLE_API_KEY'] = google_key
            
            st.markdown("### üîÆ DeepSeek")
            deepseek_key = st.text_input("DeepSeek API Key:", type="password",
                                        value=os.getenv('DEEPSEEK_API_KEY', ''),
                                        key="deepseek_key")
            if deepseek_key:
                os.environ['DEEPSEEK_API_KEY'] = deepseek_key
        
        # Status das API Keys
        st.markdown("---")
        st.subheader("üìä Status das API Keys")
        
        keys_status = {
            "ü§ñ OpenAI": bool(os.getenv('OPENAI_API_KEY')),
            "üß† Google Gemini": bool(os.getenv('GOOGLE_API_KEY')),
            "üåê OpenRouter": bool(os.getenv('OPENROUTER_API_KEY')),
            "üîÆ DeepSeek": bool(os.getenv('DEEPSEEK_API_KEY'))
        }
        
        cols = st.columns(4)
        for i, (provider, configured) in enumerate(keys_status.items()):
            with cols[i]:
                status = "‚úÖ Ativa" if configured else "‚ùå Inativa"
                color = "#28a745" if configured else "#dc3545"
                st.markdown(f"""
                <div style="text-align: center; padding: 10px; border: 1px solid {color}; border-radius: 5px; margin: 5px;">
                    <strong>{provider}</strong><br>
                    <span style="color: {color};">{status}</span>
                </div>
                """, unsafe_allow_html=True)
    
    with tab2:
        st.subheader("üß™ Testes de Conectividade")
        
        st.info("üîç Teste a conectividade e funcionamento dos provedores LLM")
        
        # Sele√ß√£o de provedores para teste
        providers_to_test = st.multiselect(
            "Selecione os provedores para testar:",
            ["openai", "google", "openrouter", "deepseek"],
            default=["openai"]
        )
        
        test_message = st.text_input("Mensagem de teste:", 
                                    value="Ol√°, este √© um teste de conectividade. Responda apenas 'OK'.")
        
        if st.button("üöÄ Executar Testes"):
            if providers_to_test:
                st.markdown("### üìä Resultados dos Testes")
                
                for provider in providers_to_test:
                    with st.expander(f"üß™ Teste: {provider.upper()}"):
                        try:
                            # Testar conectividade
                            start_time = time.time()
                            
                            # Simular teste (voc√™ pode implementar teste real aqui)
                            messages = [{"role": "user", "content": test_message}]
                            
                            # Verificar se tem API key
                            key_map = {
                                'openai': 'OPENAI_API_KEY',
                                'google': 'GOOGLE_API_KEY', 
                                'openrouter': 'OPENROUTER_API_KEY',
                                'deepseek': 'DEEPSEEK_API_KEY'
                            }
                            
                            if not os.getenv(key_map.get(provider, '')):
                                st.error(f"‚ùå API Key n√£o configurada para {provider}")
                                continue
                            
                            # Tentar gerar resposta
                            try:
                                response = rag_system.llm_manager.generate_response(
                                    messages, 
                                    provider=provider,
                                    model="gpt-3.5-turbo" if provider == "openai" else None
                                )
                                
                                end_time = time.time()
                                response_time = round(end_time - start_time, 2)
                                
                                st.success(f"‚úÖ **Sucesso!** Tempo: {response_time}s")
                                st.write(f"**Resposta:** {response}")
                                
                                # M√©tricas
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("‚è±Ô∏è Tempo", f"{response_time}s")
                                with col2:
                                    st.metric("üìä Status", "‚úÖ OK")
                                with col3:
                                    st.metric("üìù Caracteres", len(response))
                                    
                            except Exception as e:
                                st.error(f"‚ùå **Erro na resposta:** {str(e)}")
                                
                        except Exception as e:
                            st.error(f"‚ùå **Erro no teste:** {str(e)}")
            else:
                st.warning("‚ö†Ô∏è Selecione pelo menos um provedor para testar.")
        
        # Teste de compara√ß√£o r√°pida
        st.markdown("---")
        st.subheader("‚ö° Teste R√°pido Multi-LLM")
        
        if st.button("üîÑ Comparar Todos os Provedores"):
            test_question = "Qual √© a capital do Brasil?"
            
            with st.spinner("üîÑ Testando todos os provedores..."):
                results = {}
                
                for provider in ["openai", "google", "openrouter", "deepseek"]:
                    try:
                        key_map = {
                            'openai': 'OPENAI_API_KEY',
                            'google': 'GOOGLE_API_KEY', 
                            'openrouter': 'OPENROUTER_API_KEY',
                            'deepseek': 'DEEPSEEK_API_KEY'
                        }
                        
                        if os.getenv(key_map.get(provider, '')):
                            start_time = time.time()
                            
                            messages = [{"role": "user", "content": test_question}]
                            response = rag_system.llm_manager.generate_response(
                                messages, 
                                provider=provider
                            )
                            
                            end_time = time.time()
                            
                            results[provider] = {
                                'response': response,
                                'time': round(end_time - start_time, 2),
                                'status': 'success'
                            }
                        else:
                            results[provider] = {
                                'response': 'API Key n√£o configurada',
                                'time': 0,
                                'status': 'error'
                            }
                            
                    except Exception as e:
                        results[provider] = {
                            'response': f'Erro: {str(e)}',
                            'time': 0,
                            'status': 'error'
                        }
                
                # Mostrar resultados
                st.markdown("### üìä Resultados da Compara√ß√£o")
                
                for provider, result in results.items():
                    with st.expander(f"üì± {provider.upper()} - {'‚úÖ' if result['status'] == 'success' else '‚ùå'}"):
                        if result['status'] == 'success':
                            col1, col2 = st.columns([3, 1])
                            with col1:
                                st.write(f"**Resposta:** {result['response']}")
                            with col2:
                                st.metric("‚è±Ô∏è Tempo", f"{result['time']}s")
                        else:
                            st.error(result['response'])
    
    with tab3:
        st.subheader("üéõÔ∏è Configura√ß√µes Gerais")
        
        # Configura√ß√µes do modelo padr√£o
        col1, col2 = st.columns(2)
        
        with col1:
            default_model = st.selectbox("ü§ñ Modelo Padr√£o:", [
                "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview", "gpt-4o-mini",
                "gemini-pro", "deepseek-chat"
            ], index=0)
            
            default_temperature = st.slider("üå°Ô∏è Temperatura Padr√£o:", 0.0, 2.0, 0.7, 0.1)
        
        with col2:
            max_tokens = st.number_input("üìù Max Tokens:", min_value=100, max_value=4000, value=1000)
            
            debug_mode = st.checkbox("üêõ Modo Debug", value=False)
        
        # Configura√ß√µes avan√ßadas
        st.markdown("---")
        st.subheader("üîß Configura√ß√µes Avan√ßadas")
        
        col1, col2 = st.columns(2)
        
        with col1:
            timeout_duration = st.number_input("‚è±Ô∏è Timeout (segundos):", min_value=5, max_value=300, value=30)
            retry_attempts = st.number_input("üîÑ Tentativas de Retry:", min_value=1, max_value=10, value=3)
        
        with col2:
            enable_logging = st.checkbox("üìù Habilitar Logging", value=True)
            enable_cache = st.checkbox("üíæ Habilitar Cache", value=True)
        
        if st.button("üíæ Salvar Configura√ß√µes"):
            rag_system.settings.update({
                'model_name': default_model,
                'temperature': default_temperature,
                'max_tokens': max_tokens,
                'debug_mode': debug_mode,
                'timeout': timeout_duration,
                'retry_attempts': retry_attempts,
                'enable_logging': enable_logging,
                'enable_cache': enable_cache
            })
            st.success("‚úÖ Configura√ß√µes salvas com sucesso!")
    
    with tab4:
        st.subheader("üíæ Backup e Restaura√ß√£o")
        
        # Informa√ß√µes do sistema
        st.markdown("### üìä Informa√ß√µes do Sistema")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("üìÑ Documentos", len(rag_system.documents))
        
        with col2:
            try:
                agents = rag_system.agent_manager.get_all_agents()
                st.metric("ü§ñ Agentes", len(agents))
            except:
                st.metric("ü§ñ Agentes", "N/A")
        
        with col3:
            configured_keys = sum([
                bool(os.getenv('OPENAI_API_KEY')),
                bool(os.getenv('GOOGLE_API_KEY')),
                bool(os.getenv('OPENROUTER_API_KEY')),
                bool(os.getenv('DEEPSEEK_API_KEY'))
            ])
            st.metric("üîë API Keys", f"{configured_keys}/4")
        
        st.markdown("---")
        
        # Export
        if st.button("üì• Exportar Configura√ß√µes"):
            config_data = {
                'settings': rag_system.settings,
                'documents_count': len(rag_system.documents),
                'api_keys_configured': configured_keys,
                'export_date': datetime.now().isoformat(),
                'version': '1.5.1-unified'
            }
            
            st.download_button(
                label="üíæ Download Configura√ß√µes",
                data=json.dumps(config_data, indent=2),
                file_name=f"rag_config_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        
        # Import
        uploaded_config = st.file_uploader("üì§ Importar Configura√ß√µes:", type=['json'])
        
        if uploaded_config and st.button("üì• Restaurar Configura√ß√µes"):
            try:
                config_data = json.load(uploaded_config)
                rag_system.settings.update(config_data.get('settings', {}))
                st.success("‚úÖ Configura√ß√µes restauradas com sucesso!")
                st.info(f"üìä Importado de: {config_data.get('export_date', 'N/A')}")
            except Exception as e:
                st.error(f"‚ùå Erro ao importar configura√ß√µes: {str(e)}")

if __name__ == "__main__":
    main() 