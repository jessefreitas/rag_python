"""
ğŸš€ RAG PYTHON v1.5.1 - SISTEMA COMPLETO UNIFICADO
Sistema RAG com Multi-LLM, Agentes, Privacidade LGPD e Dashboard
Todas as funcionalidades em uma Ãºnica interface
"""

import streamlit as st
import os
import tempfile
import json
import uuid
from pathlib import Path
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import psycopg2
import psycopg2.extras
import time

# ImportaÃ§Ãµes do sistema
from llm_providers import LLMProviderManager
from privacy_system import privacy_manager
from vector_store import VectorStore
from database import Database

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="ğŸš€ RAG Python v1.5.1 - Sistema Completo",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        background: linear-gradient(90deg, #1f77b4, #ff7f0e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    .feature-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        margin-bottom: 1rem;
        border-left: 4px solid #1f77b4;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        border-left: 4px solid #1f77b4;
    }
    .user-message {
        background-color: #e3f2fd;
        border-left-color: #2196f3;
    }
    .assistant-message {
        background-color: #f3e5f5;
        border-left-color: #9c27b0;
    }
    .provider-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 0.5rem;
    }
    .agent-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 0.5rem;
    }
    .privacy-alert {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
        color: #155724;
    }
    .info-box {
        background-color: #e8f5e8;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #4caf50;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 2px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        padding-left: 20px;
        padding-right: 20px;
        background-color: #f0f2f6;
        border-radius: 10px 10px 0px 0px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #1f77b4;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

class AgentManager:
    """Gerenciador de Agentes com funcionalidades completas"""
    
    def __init__(self):
        self.llm_manager = LLMProviderManager()
    
    @staticmethod
    def _execute_query(query: str, params: tuple = (), fetch: Optional[str] = None):
        """Executa query no banco de dados"""
        conn = None
        try:
            conn = Database.get_connection()
            with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:
                cur.execute(query, params)
                if fetch == 'one':
                    result = cur.fetchone()
                elif fetch == 'all':
                    result = cur.fetchall()
                else:
                    result = None
                conn.commit()
                return result
        except Exception as e:
            logger.error(f"Database query failed: {e}")
            if conn: conn.rollback()
            return None
        finally:
            if conn: Database.release_connection(conn)
    
    def create_agent(self, name: str, description: str, agent_type: str, system_prompt: str, 
                    model: str = "gpt-3.5-turbo", temperature: float = 0.7) -> Optional[str]:
        """Cria um novo agente"""
        try:
            query = """
                INSERT INTO agentes (name, description, system_prompt, model, temperature, agent_type) 
                VALUES (%s, %s, %s, %s, %s, %s) RETURNING id;
            """
            params = (name, description, system_prompt, model, temperature, agent_type)
            result = self._execute_query(query, params, fetch='one')
            return str(result['id']) if result else None
        except Exception as e:
            logger.error(f"Erro ao criar agente: {e}")
            return None
    
    def get_all_agents(self) -> List[Dict]:
        """Lista todos os agentes"""
        try:
            query = "SELECT * FROM agentes ORDER BY created_at DESC"
            rows = self._execute_query(query, fetch='all')
            agents = []
            for row in rows:
                agent_data = dict(row)
                # Converter Decimal para float se necessÃ¡rio
                if 'temperature' in agent_data:
                    agent_data['temperature'] = float(agent_data['temperature'])
                agents.append(agent_data)
            return agents
        except Exception as e:
            logger.error(f"Erro ao listar agentes: {e}")
            return []
    
    def get_agent_by_id(self, agent_id: str) -> Optional[Dict]:
        """ObtÃ©m agente por ID"""
        try:
            query = "SELECT * FROM agentes WHERE id = %s"
            row = self._execute_query(query, (agent_id,), fetch='one')
            if row:
                agent_data = dict(row)
                # Converter Decimal para float se necessÃ¡rio
                if 'temperature' in agent_data:
                    agent_data['temperature'] = float(agent_data['temperature'])
                return agent_data
            return None
        except Exception as e:
            logger.error(f"Erro ao buscar agente: {e}")
            return None
    
    def update_agent(self, agent_id: str, data: Dict) -> bool:
        """Atualiza um agente"""
        try:
            query = """
                UPDATE agentes SET name = %s, description = %s, system_prompt = %s, 
                model = %s, temperature = %s WHERE id = %s
            """
            params = (data['name'], data['description'], data['system_prompt'], 
                     data['model'], data['temperature'], agent_id)
            self._execute_query(query, params)
            return True
        except Exception as e:
            logger.error(f"Erro ao atualizar agente: {e}")
            return False
    
    def delete_agent(self, agent_id: str) -> bool:
        """Deleta um agente"""
        try:
            query = "DELETE FROM agentes WHERE id = %s"
            self._execute_query(query, (agent_id,))
            return True
        except Exception as e:
            logger.error(f"Erro ao deletar agente: {e}")
            return False

class RAGSystemUnified:
    """Sistema RAG unificado com todas as funcionalidades"""
    
    def __init__(self):
        self.llm_manager = LLMProviderManager()
        self.agent_manager = AgentManager()
        self.documents = []
        self.knowledge_base = {}
        self.settings = {
            'model_name': 'gpt-3.5-turbo',
            'temperature': 0.7,
            'max_tokens': 1000
        }
        self.connection_pool = self._create_connection_pool()
        self._create_tables()
    
    def _create_connection_pool(self):
        """Cria pool de conexÃµes com PostgreSQL"""
        try:
            return psycopg2.pool.SimpleConnectionPool(
                1, 20,
                host=os.getenv('POSTGRES_HOST', 'localhost'),
                database=os.getenv('POSTGRES_DB', 'rag_system'),
                user=os.getenv('POSTGRES_USER', 'postgres'),
                password=os.getenv('POSTGRES_PASSWORD', 'postgres'),
                port=os.getenv('POSTGRES_PORT', '5432')
            )
        except Exception as e:
            logger.error(f"Erro ao criar pool de conexÃµes: {e}")
            return None
    
    def _create_tables(self):
        """Cria tabelas necessÃ¡rias se nÃ£o existirem"""
        try:
            create_agents_table = """
                CREATE TABLE IF NOT EXISTS agentes (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    name VARCHAR(255) NOT NULL,
                    description TEXT,
                    agent_type VARCHAR(100),
                    system_prompt TEXT NOT NULL,
                    model VARCHAR(100) DEFAULT 'gpt-3.5-turbo',
                    temperature DECIMAL(3,2) DEFAULT 0.7,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """
            
            create_documents_table = """
                CREATE TABLE IF NOT EXISTS documents (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    name VARCHAR(255) NOT NULL,
                    content TEXT,
                    file_type VARCHAR(50),
                    file_size INTEGER,
                    agent_id UUID REFERENCES agentes(id) ON DELETE CASCADE,
                    upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    processed BOOLEAN DEFAULT FALSE,
                    vector_store_id VARCHAR(255)
                );
            """
            
            create_index = """
                CREATE INDEX IF NOT EXISTS idx_documents_agent_id ON documents(agent_id);
                CREATE INDEX IF NOT EXISTS idx_documents_upload_date ON documents(upload_date);
            """
            
            self._execute_query(create_agents_table)
            self._execute_query(create_documents_table)
            self._execute_query(create_index)
            
            logger.info("Tabelas criadas/verificadas com sucesso")
            
        except Exception as e:
            logger.error(f"Erro ao criar tabelas: {e}")
    
    def query_with_agent(self, question: str, agent_id: str = None, llm: str = None) -> Dict:
        """Processa pergunta com agente especÃ­fico e LLM escolhido"""
        try:
            import time
            start_time = time.time()
            
            agent = None
            if agent_id:
                agent = self.agent_manager.get_agent_by_id(agent_id)
            
            # Recuperar documentos do agente
            context_docs = self.get_agent_documents(agent_id) if agent_id else []
            
            # Preparar contexto dos documentos
            context = ""
            if context_docs:
                context = "\n\nContexto dos documentos:\n"
                for doc in context_docs[:3]:  # Limitar a 3 documentos mais relevantes
                    context += f"- {doc.get('name', 'Documento')}: {doc.get('content', '')[:500]}...\n"
            
            # Preparar mensagens
            messages = []
            
            if agent:
                system_prompt = agent['system_prompt']
                if context:
                    system_prompt += f"\n\nUse os seguintes documentos como referÃªncia quando relevante:{context}"
                
                messages.append({
                    "role": "system", 
                    "content": system_prompt
                })
            elif context:
                messages.append({
                    "role": "system",
                    "content": f"VocÃª Ã© um assistente inteligente. Use os seguintes documentos como referÃªncia quando relevante:{context}"
                })
            
            messages.append({"role": "user", "content": question})
            
            # Determinar configuraÃ§Ãµes
            if agent:
                model = agent['model']
                temperature = float(agent['temperature'])
            else:
                model = self.settings['model_name']
                temperature = float(self.settings['temperature'])
            
            # Gerar resposta usando LLM especificado
            if llm:
                result = self.llm_manager.generate_response(
                    messages,
                    provider_name=llm,
                    model=model,
                    temperature=temperature
                )
                
                if result.get('success'):
                    end_time = time.time()
                    return {
                        'answer': result['response'],
                        'agent_used': agent['name'] if agent else 'Sistema PadrÃ£o',
                        'model_used': result.get('model', model),
                        'llm_used': llm,
                        'response_time': round(end_time - start_time, 2),
                        'documents_used': len(context_docs),
                        'success': True
                    }
                else:
                    return {
                        'answer': f"Erro: {result.get('error', 'Erro desconhecido')}",
                        'agent_used': agent['name'] if agent else 'Sistema PadrÃ£o',
                        'model_used': model,
                        'llm_used': llm,
                        'response_time': 0,
                        'documents_used': 0,
                        'success': False
                    }
            else:
                # Usar mÃ©todo legado
                response = self.llm_manager.generate_response_old(
                    messages,
                    model=model,
                    temperature=temperature
                )
                
                end_time = time.time()
                return {
                    'answer': response,
                    'agent_used': agent['name'] if agent else 'Sistema PadrÃ£o',
                    'model_used': model,
                    'llm_used': 'padrÃ£o',
                    'response_time': round(end_time - start_time, 2),
                    'documents_used': len(context_docs),
                    'success': True
                }
            
        except Exception as e:
            logger.error(f"Erro ao processar pergunta: {e}")
            return {
                'answer': f"Erro: {str(e)}",
                'agent_used': 'Erro',
                'model_used': 'N/A',
                'llm_used': llm or 'N/A',
                'response_time': 0,
                'documents_used': 0,
                'success': False
            }
    
    def get_agent_documents(self, agent_id: str = None) -> List[Dict]:
        """Recupera documentos associados a um agente especÃ­fico"""
        try:
            if not agent_id:
                # Retornar documentos da base geral
                return [doc for doc in self.documents if not doc.get('agent_id')]
            
            # Buscar documentos no banco de dados PostgreSQL (usando schema correto)
            query = """
                SELECT d.id, d.file_name, d.source_type, d.content_hash, d.created_at, d.agent_id,
                       COUNT(dc.id) as chunk_count
                FROM documents d
                LEFT JOIN document_chunks dc ON d.id = dc.document_id
                WHERE d.agent_id = %s 
                GROUP BY d.id, d.file_name, d.source_type, d.content_hash, d.created_at, d.agent_id
                ORDER BY d.created_at DESC
            """
            
            rows = self.agent_manager._execute_query(query, (agent_id,), fetch='all')
            
            if rows:
                documents = []
                for row in rows:
                    documents.append({
                        'id': str(row[0]),
                        'name': row[1] or 'Documento sem nome',
                        'file_type': row[2] or 'unknown',
                        'content_hash': row[3],
                        'upload_date': row[4],
                        'agent_id': str(row[5]),
                        'chunk_count': row[6] or 0
                    })
                return documents
            else:
                # Fallback para documentos em memÃ³ria
                return [doc for doc in self.documents if doc.get('agent_id') == agent_id]
                
        except Exception as e:
            logger.error(f"Erro ao recuperar documentos do agente {agent_id}: {e}")
            # Fallback para documentos em memÃ³ria
            if agent_id:
                return [doc for doc in self.documents if doc.get('agent_id') == agent_id]
            else:
                return [doc for doc in self.documents if not doc.get('agent_id')]
    
    def multi_llm_compare(self, question: str, providers: List[str] = None) -> Dict:
        """Compara respostas de mÃºltiplos LLMs"""
        try:
            if not providers:
                providers = ['openai', 'google', 'openrouter', 'deepseek']
            
            messages = [{"role": "user", "content": question}]
            
            results = self.llm_manager.compare_multi_llm(
                messages, 
                providers=providers,
                model=self.settings['model_name'],
                temperature=self.settings['temperature']
            )
            
            return results
            
        except Exception as e:
            logger.error(f"Erro na comparaÃ§Ã£o Multi-LLM: {e}")
            return {'error': str(e)}

@st.cache_resource
def initialize_system():
    """Inicializa o sistema unificado"""
    return RAGSystemUnified()

def main():
    """Interface principal do sistema"""
    
    # Inicializar sistema
    rag_system = initialize_system()
    
    # Header principal
    st.markdown('<h1 class="main-header">ğŸš€ RAG Python v1.5.1 - Sistema Completo</h1>', 
                unsafe_allow_html=True)
    
    # Tabs principais
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ  Dashboard",
        "ğŸ’¬ Chat RAG", 
        "ğŸ¤– Agentes",
        "ğŸ”„ Multi-LLM",
        "ğŸ”’ Privacidade",
        "ğŸ“ Documentos",
        "âš™ï¸ ConfiguraÃ§Ãµes"
    ])
    
    with tab1:
        dashboard_interface(rag_system)
    
    with tab2:
        chat_rag_interface(rag_system)
    
    with tab3:
        agents_interface(rag_system)
    
    with tab4:
        multi_llm_interface(rag_system)
    
    with tab5:
        privacy_interface(rag_system)
    
    with tab6:
        documents_interface(rag_system)
    
    with tab7:
        settings_interface(rag_system)

def dashboard_interface(rag_system):
    """Interface do Dashboard"""
    st.header("ğŸ“Š Dashboard do Sistema")
    
    # MÃ©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        try:
            agents = rag_system.agent_manager.get_all_agents()
            st.metric("ğŸ¤– Agentes", len(agents), help="Agentes especializados cadastrados")
        except:
            st.metric("ğŸ¤– Agentes", "N/A", help="Erro ao carregar agentes")
    
    with col2:
        st.metric("ğŸ“„ Documentos", len(rag_system.documents), help="Documentos na base de conhecimento")
    
    with col3:
        configured_keys = sum([
            bool(os.getenv('OPENAI_API_KEY')),
            bool(os.getenv('GOOGLE_API_KEY')),
            bool(os.getenv('OPENROUTER_API_KEY')),
            bool(os.getenv('DEEPSEEK_API_KEY'))
        ])
        st.metric("ğŸ”‘ API Keys", f"{configured_keys}/4", help="API Keys configuradas")
    
    with col4:
        try:
            providers_info = rag_system.llm_manager.get_provider_info()
            active_providers = 0
            for info in providers_info.values():
                if isinstance(info, dict) and info.get('available', False):
                    active_providers += 1
            st.metric("ğŸŒ Provedores", f"{active_providers}/4", help="Provedores LLM ativos")
        except:
            st.metric("ğŸŒ Provedores", "N/A", help="Erro ao verificar provedores")
    
    # Status dos provedores LLM
    st.markdown("---")
    st.subheader("ğŸŒ Status dos Provedores LLM")
    
    # Verificar status das API keys
    providers_status = {
        "OpenAI": {
            "key": bool(os.getenv('OPENAI_API_KEY')),
            "icon": "ğŸ¤–",
            "models": ["gpt-3.5-turbo", "gpt-4", "gpt-4o-mini"]
        },
        "Google Gemini": {
            "key": bool(os.getenv('GOOGLE_API_KEY')),
            "icon": "ğŸ§ ",
            "models": ["gemini-pro", "gemini-1.5-flash"]
        },
        "OpenRouter": {
            "key": bool(os.getenv('OPENROUTER_API_KEY')),
            "icon": "ğŸŒ",
            "models": ["claude-3", "llama-2", "mixtral"]
        },
        "DeepSeek": {
            "key": bool(os.getenv('DEEPSEEK_API_KEY')),
            "icon": "ğŸ”®",
            "models": ["deepseek-chat", "deepseek-coder"]
        }
    }
    
    cols = st.columns(4)
    for i, (provider, info) in enumerate(providers_status.items()):
        with cols[i]:
            status = "âœ… Ativo" if info['key'] else "âŒ Inativo"
            color = "#d4edda" if info['key'] else "#f8d7da"
            border_color = "#28a745" if info['key'] else "#dc3545"
            
            st.markdown(f"""
            <div style="
                background-color: {color}; 
                border: 2px solid {border_color}; 
                border-radius: 10px; 
                padding: 15px; 
                text-align: center;
                margin: 5px;
                min-height: 120px;
            ">
                <h3 style="margin: 0;">{info['icon']} {provider}</h3>
                <p style="margin: 5px 0; font-weight: bold;">{status}</p>
                <small>Modelos: {len(info['models'])}</small>
            </div>
            """, unsafe_allow_html=True)
    
    # Funcionalidades do sistema
    st.markdown("---")
    st.subheader("ğŸš€ Funcionalidades DisponÃ­veis")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        ### ğŸ’¬ Chat RAG
        - ConversaÃ§Ã£o inteligente com agentes
        - Busca em base de conhecimento
        - HistÃ³rico de conversas
        
        ### ğŸ¤– Sistema de Agentes
        - Agentes especializados por domÃ­nio
        - ConfiguraÃ§Ã£o personalizada
        - Prompts otimizados
        """)
    
    with col2:
        st.markdown("""
        ### ğŸ”„ Multi-LLM
        - ComparaÃ§Ã£o entre 4 provedores
        - MÃ©tricas de performance
        - AnÃ¡lise de qualidade
        
        ### ğŸ”’ Privacidade LGPD
        - DetecÃ§Ã£o de dados sensÃ­veis
        - AnonimizaÃ§Ã£o automÃ¡tica
        - Compliance reports
        """)
    
    # AÃ§Ãµes rÃ¡pidas
    st.markdown("---")
    st.subheader("âš¡ AÃ§Ãµes RÃ¡pidas")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("ğŸ”§ Configurar APIs", help="Ir para configuraÃ§Ãµes de API"):
            st.info("ğŸ’¡ Use a aba **âš™ï¸ ConfiguraÃ§Ãµes** acima para configurar APIs")
    
    with col2:
        if st.button("ğŸ¤– Criar Agente", help="Criar novo agente"):
            st.info("ğŸ’¡ Use a aba **ğŸ¤– Agentes** acima para criar agentes")
    
    with col3:
        if st.button("ğŸ“¤ Upload Docs", help="Fazer upload de documentos"):
            st.info("ğŸ’¡ Use a aba **ğŸ“ Documentos** acima para upload")
    
    with col4:
        if st.button("ğŸ§ª Testar LLMs", help="Testar conectividade"):
            st.info("ğŸ’¡ Use a aba **âš™ï¸ ConfiguraÃ§Ãµes** > **ğŸ§ª Testes** para testar LLMs")
    
    # InformaÃ§Ãµes do sistema
    st.markdown("---")
    st.subheader("â„¹ï¸ InformaÃ§Ãµes do Sistema")
    
    info_col1, info_col2 = st.columns(2)
    
    with info_col1:
        st.info("""
        **ğŸš€ RAG Python v1.5.1-Unified**
        
        Sistema completo de RAG com:
        - Multi-LLM integration
        - Sistema de agentes especializados
        - Compliance LGPD
        - Interface unificada
        """)
    
    with info_col2:
        st.success("""
        **âœ… Sistema Operacional**
        
        Status:
        - âœ… Interface carregada
        - âœ… Banco PostgreSQL conectado
        - âœ… Sistema de arquivos OK
        - âœ… Pronto para uso
        """)

def chat_rag_interface(rag_system):
    """Interface do Chat RAG"""
    st.header("ğŸ’¬ Chat RAG Inteligente")
    
    # ConfiguraÃ§Ã£o em duas colunas
    col1, col2 = st.columns([1, 1])
    
    with col1:
        # SeleÃ§Ã£o de agente
        agents = rag_system.agent_manager.get_all_agents()
        agent_options = {"Sistema PadrÃ£o": None}
        agent_options.update({agent['name']: agent['id'] for agent in agents})
        
        selected_agent = st.selectbox("ğŸ¤– Selecionar Agente:", list(agent_options.keys()))
        agent_id = agent_options[selected_agent]
    
    with col2:
        # SeleÃ§Ã£o de LLM
        llm_options = {
            "ğŸ¤– OpenAI (GPT)": "openai",
            "ğŸ” Google Gemini": "google", 
            "ğŸŒ OpenRouter": "openrouter",
            "ğŸ§  DeepSeek": "deepseek"
        }
        
        selected_llm_display = st.selectbox("ğŸ”§ Selecionar LLM:", list(llm_options.keys()))
        selected_llm = llm_options[selected_llm_display]
    
    # Mostrar configuraÃ§Ã£o atual
    if agent_id:
        agent = rag_system.agent_manager.get_agent_by_id(agent_id)
        if agent:
            st.info(f"ğŸ¤– **Agente:** {agent['name']} | **LLM:** {selected_llm_display} | **Documentos:** {len(rag_system.get_agent_documents(agent_id))} docs")
    else:
        st.info(f"ğŸ¤– **Sistema PadrÃ£o** | **LLM:** {selected_llm_display} | **Base:** Geral")
    
    # HistÃ³rico do chat
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    # Ãrea de mensagens
    chat_container = st.container()
    
    with chat_container:
        for message in st.session_state.chat_history:
            if message['role'] == 'user':
                with st.chat_message("user"):
                    st.write(message['content'])
            else:
                with st.chat_message("assistant"):
                    st.write(message['content'])
                    st.caption(f"ğŸ¤– {message.get('agent', 'Sistema')} | ğŸ”§ {message.get('llm', 'N/A')} | âš¡ {message.get('response_time', 0):.2f}s")
    
    # Input de mensagem com suporte ao Enter
    user_input = st.chat_input("ğŸ’­ Digite sua pergunta...")
    
    # Processar mensagem quando Enter for pressionado
    if user_input:
        # Adicionar mensagem do usuÃ¡rio
        st.session_state.chat_history.append({
            'role': 'user',
            'content': user_input
        })
        
        # Processar resposta
        with st.spinner("ğŸ¤” Pensando..."):
            result = rag_system.query_with_agent(user_input, agent_id, selected_llm)
        
        # Adicionar resposta do assistente
        if result['success']:
            st.session_state.chat_history.append({
                'role': 'assistant',
                'content': result['answer'],
                'agent': result.get('agent_used', selected_agent),
                'llm': selected_llm_display,
                'response_time': result.get('response_time', 0)
            })
        else:
            st.session_state.chat_history.append({
                'role': 'assistant',
                'content': f"âŒ Erro: {result.get('answer', 'Erro desconhecido')}",
                'agent': result.get('agent_used', selected_agent),
                'llm': selected_llm_display,
                'response_time': 0
            })
        
        st.rerun()
    
    # BotÃµes de aÃ§Ã£o
    col1, col2, col3 = st.columns([1, 1, 2])
    
    with col1:
        if st.button("ğŸ—‘ï¸ Limpar Chat"):
            st.session_state.chat_history = []
            st.rerun()
    
    with col2:
        if st.button("ğŸ“Š Ver Documentos"):
            if agent_id:
                docs = rag_system.get_agent_documents(agent_id)
                st.info(f"ğŸ“š {len(docs)} documentos na base do agente")
                for doc in docs[:3]:  # Mostrar primeiros 3
                    st.write(f"ğŸ“„ {doc.get('name', 'Documento')}")
            else:
                st.info("ğŸ“š Base de documentos geral")
    
    with col3:
        st.write("")  # EspaÃ§o

def agents_interface(rag_system):
    """Interface de gerenciamento de agentes"""
    st.header("ğŸ¤– Sistema de Agentes Especializados")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ Lista de Agentes", "â• Criar Agente", "âš™ï¸ Configurar Agente"])
    
    with tab1:
        st.subheader("ğŸ‘¥ Agentes Cadastrados")
        
        agents = rag_system.agent_manager.get_all_agents()
        
        if agents:
            for agent in agents:
                with st.expander(f"ğŸ¤– {agent['name']} - {agent.get('agent_type', 'Geral')}"):
                    col1, col2 = st.columns([3, 1])
                    
                    with col1:
                        st.write(f"**DescriÃ§Ã£o:** {agent['description']}")
                        st.write(f"**Modelo:** {agent['model']}")
                        st.write(f"**Temperatura:** {agent['temperature']}")
                        st.write(f"**Criado em:** {agent.get('created_at', 'N/A')}")
                        
                        with st.expander("Ver Prompt do Sistema"):
                            st.code(agent['system_prompt'], language='text')
                    
                    with col2:
                        if st.button("ğŸ—‘ï¸ Deletar", key=f"delete_{agent['id']}"):
                            if rag_system.agent_manager.delete_agent(agent['id']):
                                st.success("Agente deletado com sucesso!")
                                st.rerun()
        else:
            st.info("ğŸ“ Nenhum agente cadastrado ainda. Crie seu primeiro agente!")
    
    with tab2:
        st.subheader("â• Criar Novo Agente")
        
        with st.form("create_agent_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                agent_name = st.text_input("ğŸ·ï¸ Nome do Agente", placeholder="Ex: Assistente JurÃ­dico")
                agent_type = st.selectbox("ğŸ¯ Tipo de Agente", [
                    "Conversacional", "Pesquisador", "Executor", "Especialista"
                ])
                model = st.selectbox("ğŸ¤– Modelo LLM", [
                    "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview", "gpt-4o-mini",
                    "gemini-pro", "gemini-pro-vision", "deepseek-chat", "deepseek-coder"
                ])
            
            with col2:
                temperature = st.slider("ğŸŒ¡ï¸ Temperatura", 0.0, 2.0, 0.7, 0.1)
                description = st.text_area("ğŸ“ DescriÃ§Ã£o", 
                                         placeholder="Descreva o propÃ³sito e especialidade do agente")
            
            system_prompt = st.text_area("ğŸ­ Prompt do Sistema", height=200,
                                       placeholder="Defina o comportamento e especialidade do agente...")
            
            if st.form_submit_button("ğŸš€ Criar Agente", type="primary"):
                if agent_name and system_prompt:
                    agent_id = rag_system.agent_manager.create_agent(
                        name=agent_name,
                        description=description,
                        agent_type=agent_type,
                        system_prompt=system_prompt,
                        model=model,
                        temperature=temperature
                    )
                    
                    if agent_id:
                        st.success(f"âœ… Agente '{agent_name}' criado com sucesso!")
                        st.balloons()
                        st.rerun()
                    else:
                        st.error("âŒ Erro ao criar agente. Verifique a conexÃ£o com banco de dados.")
                else:
                    st.error("âš ï¸ Preencha pelo menos o nome e o prompt do sistema.")
    
    with tab3:
        st.subheader("âš™ï¸ Configurar Agente Existente")
        
        agents = rag_system.agent_manager.get_all_agents()
        if agents:
            agent_to_edit = st.selectbox("Selecionar Agente:", 
                                       [f"{a['name']} (ID: {a['id']})" for a in agents])
            
            if agent_to_edit:
                agent_id = agent_to_edit.split("ID: ")[1].rstrip(")")
                agent = rag_system.agent_manager.get_agent_by_id(agent_id)
                
                if agent:
                    with st.form("edit_agent_form"):
                        new_name = st.text_input("Nome", value=agent['name'])
                        new_description = st.text_area("DescriÃ§Ã£o", value=agent['description'])
                        new_model = st.selectbox("Modelo", [
                            "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview", "gpt-4o-mini",
                            "gemini-pro", "deepseek-chat"
                        ], index=0 if agent['model'] == "gpt-3.5-turbo" else 0)
                        new_temperature = st.slider("Temperatura", 0.0, 2.0, float(agent['temperature']), 0.1)
                        new_prompt = st.text_area("Prompt do Sistema", value=agent['system_prompt'], height=200)
                        
                        if st.form_submit_button("ğŸ’¾ Salvar AlteraÃ§Ãµes"):
                            update_data = {
                                'name': new_name,
                                'description': new_description,
                                'system_prompt': new_prompt,
                                'model': new_model,
                                'temperature': new_temperature
                            }
                            
                            if rag_system.agent_manager.update_agent(agent_id, update_data):
                                st.success("âœ… Agente atualizado com sucesso!")
                                st.rerun()
                            else:
                                st.error("âŒ Erro ao atualizar agente.")
        else:
            st.info("Nenhum agente disponÃ­vel para configuraÃ§Ã£o.")

def multi_llm_interface(rag_system):
    """Interface Multi-LLM com testes e comparaÃ§Ãµes"""
    st.header("ğŸ¤– Sistema Multi-LLM")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ Chat Individual", "âš–ï¸ ComparaÃ§Ã£o", "ğŸ§ª Testes"])
    
    with tab1:
        st.subheader("ğŸ’¬ Chat com Provedor EspecÃ­fico")
        
        # SeleÃ§Ã£o de provedor
        providers_available = ["openai", "google", "openrouter", "deepseek"]
        selected_provider = st.selectbox(
            "ğŸ”§ Escolher Provedor LLM:",
            providers_available,
            format_func=lambda x: {
                "openai": "ğŸ¤– OpenAI (GPT)",
                "google": "ğŸ” Google Gemini", 
                "openrouter": "ğŸŒ OpenRouter",
                "deepseek": "ğŸ§  DeepSeek"
            }.get(x, x.upper())
        )
        
        # SeleÃ§Ã£o de agente
        agents = rag_system.agent_manager.get_all_agents()
        agent_options = {"Sistema PadrÃ£o": None}
        agent_options.update({f"{agent['name']} (ID: {agent['id'][:8]}...)": agent['id'] for agent in agents})
        
        selected_agent_option = st.selectbox(
            "ğŸ¤– Escolher Agente:",
            list(agent_options.keys()),
            help="Selecione qual agente especializado usar para a conversa"
        )
        selected_agent_id = agent_options[selected_agent_option]
        
        # Mostrar info do agente selecionado
        if selected_agent_id:
            agent = rag_system.agent_manager.get_agent_by_id(selected_agent_id)
            if agent:
                st.info(f"ğŸ¤– **Agente:** {agent['name']} | **Tipo:** {agent.get('agent_type', 'N/A')} | **Modelo:** {agent.get('model', 'N/A')}")
        else:
            st.info(f"ğŸ¤– **Sistema PadrÃ£o** | **Provedor:** {selected_provider.upper()}")
        
        # Chat input
        user_question = st.chat_input("ğŸ’­ Digite sua pergunta...")
        
        # Inicializar histÃ³rico se nÃ£o existir
        if f"chat_history_{selected_provider}" not in st.session_state:
            st.session_state[f"chat_history_{selected_provider}"] = []
        
        # Processar nova mensagem
        if user_question:
            # Adicionar pergunta do usuÃ¡rio
            st.session_state[f"chat_history_{selected_provider}"].append({
                'role': 'user',
                'content': user_question
            })
            
            # Gerar resposta
            with st.spinner(f"ğŸ¤” {selected_provider.upper()} pensando..."):
                if selected_agent_id:
                    # Usar agente especÃ­fico
                    result = rag_system.query_with_agent(user_question, selected_agent_id)
                else:
                    # Usar provedor especÃ­fico
                    result = rag_system.llm_manager.generate_response(
                        user_question, 
                        provider_name=selected_provider
                    )
                
                # Adicionar resposta
                if result.get('success', False):
                    st.session_state[f"chat_history_{selected_provider}"].append({
                        'role': 'assistant',
                        'content': result.get('response', result.get('answer', 'Sem resposta')),
                        'provider': selected_provider,
                        'agent': selected_agent_option if selected_agent_id else 'Sistema PadrÃ£o',
                        'response_time': result.get('response_time', 0)
                    })
                else:
                    st.session_state[f"chat_history_{selected_provider}"].append({
                        'role': 'error',
                        'content': f"Erro: {result.get('error', 'Erro desconhecido')}",
                        'provider': selected_provider
                    })
        
        # Mostrar histÃ³rico do chat
        chat_container = st.container()
        with chat_container:
            for message in st.session_state[f"chat_history_{selected_provider}"]:
                if message['role'] == 'user':
                    st.chat_message("user").write(message['content'])
                elif message['role'] == 'assistant':
                    with st.chat_message("assistant"):
                        st.write(message['content'])
                        st.caption(f"ğŸ¤– {message.get('provider', '').upper()} | âš¡ {message.get('response_time', 0):.2f}s | ğŸ‘¤ {message.get('agent', 'N/A')}")
                elif message['role'] == 'error':
                    st.error(f"âŒ {message['content']}")
        
        # BotÃ£o para limpar chat
        if st.button(f"ğŸ—‘ï¸ Limpar Chat {selected_provider.upper()}"):
            st.session_state[f"chat_history_{selected_provider}"] = []
            st.rerun()
    
    with tab2:
        st.subheader("âš–ï¸ ComparaÃ§Ã£o Multi-LLM")
        
        # SeleÃ§Ã£o de agente para comparaÃ§Ã£o
        agents = rag_system.agent_manager.get_all_agents()
        agent_options = {"Sistema PadrÃ£o": None}
        agent_options.update({f"{agent['name']} (ID: {agent['id'][:8]}...)": agent['id'] for agent in agents})
        
        comparison_agent_option = st.selectbox(
            "ğŸ¤– Agente para ComparaÃ§Ã£o:",
            list(agent_options.keys()),
            help="Todos os provedores usarÃ£o este agente/sistema para responder",
            key="comparison_agent"
        )
        comparison_agent_id = agent_options[comparison_agent_option]
        
        # SeleÃ§Ã£o de provedores para comparaÃ§Ã£o
        providers_available = ["openai", "google", "openrouter", "deepseek"]
        selected_providers = st.multiselect(
            "ğŸ”§ Provedores para ComparaÃ§Ã£o:",
            providers_available,
            default=["openai", "google"],
            format_func=lambda x: {
                "openai": "ğŸ¤– OpenAI (GPT)",
                "google": "ğŸ” Google Gemini", 
                "openrouter": "ğŸŒ OpenRouter",
                "deepseek": "ğŸ§  DeepSeek"
            }.get(x, x.upper())
        )
        
        comparison_question = st.text_area("â“ Pergunta para ComparaÃ§Ã£o:", 
                                         placeholder="Digite uma pergunta para comparar entre os provedores...")
        
        if st.button("âš–ï¸ Comparar Provedores", type="primary"):
            if comparison_question and selected_providers:
                with st.spinner("ğŸ”„ Comparando provedores..."):
                    if comparison_agent_id:
                        # Usar agente especÃ­fico
                        results = {}
                        for provider in selected_providers:
                            try:
                                result = rag_system.query_with_agent(comparison_question, comparison_agent_id)
                                results[provider] = {
                                    'success': result.get('success', False),
                                    'response': result.get('answer', 'Sem resposta'),
                                    'response_time': result.get('response_time', 0),
                                    'error': result.get('error', None)
                                }
                            except Exception as e:
                                results[provider] = {
                                    'success': False,
                                    'response': '',
                                    'response_time': 0,
                                    'error': str(e)
                                }
                    else:
                        # Usar sistema multi-LLM
                        results = rag_system.multi_llm_compare(comparison_question, selected_providers)
                
                if isinstance(results, dict) and 'error' not in results:
                    # Mostrar resultados
                    st.subheader("ğŸ“Š Resultados da ComparaÃ§Ã£o")
                    
                    for provider in selected_providers:
                        if provider in results:
                            result = results[provider]
                            
                            with st.expander(f"ğŸ¤– {provider.upper()} - {'âœ… Sucesso' if result.get('success') else 'âŒ Erro'}"):
                                st.markdown(f"""
                                <div class="provider-result">
                                    <p><strong>â±ï¸ Tempo:</strong> {result.get('response_time', 0):.2f}s</p>
                                    <p><strong>ğŸ¤– Agente:</strong> {comparison_agent_option}</p>
                                </div>
                                """, unsafe_allow_html=True)
                                
                                # Resposta
                                if result.get('success'):
                                    st.text_area(f"Resposta {provider.upper()}:", 
                                               value=result.get('response', 'Erro na resposta'),
                                               height=200, key=f"response_{provider}")
                                else:
                                    st.error(f"Erro: {result.get('error', 'Erro desconhecido')}")
                    
                    # MÃ©tricas de comparaÃ§Ã£o
                    st.subheader("ğŸ“ˆ MÃ©tricas de Performance")
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        # Corrigir o erro IndexError
                        valid_results = {p: r for p, r in results.items() if isinstance(r, dict) and r.get('success')}
                        times = [r.get('response_time', 0) for r in valid_results.values()]
                        
                        if times:
                            fastest_time = min(times)
                            fastest_providers = [p for p, r in valid_results.items() if r.get('response_time') == fastest_time]
                            if fastest_providers:
                                fastest_provider = fastest_providers[0]
                                st.metric("âš¡ Mais RÃ¡pido", fastest_provider.upper(), f"{fastest_time:.2f}s")
                            else:
                                st.metric("âš¡ Mais RÃ¡pido", "N/A", "0.00s")
                        else:
                            st.metric("âš¡ Mais RÃ¡pido", "N/A", "0.00s")
                    
                    with col2:
                        successful = len(valid_results)
                        st.metric("âœ… Sucessos", f"{successful}/{len(selected_providers)}")
                    
                    with col3:
                        avg_time = sum(times) / len(times) if times else 0
                        st.metric("â±ï¸ Tempo MÃ©dio", f"{avg_time:.2f}s")
                
                else:
                    st.error(f"Erro na comparaÃ§Ã£o: {results.get('error', 'Erro desconhecido')}")
            else:
                if not comparison_question:
                    st.warning("âš ï¸ Digite uma pergunta para comparaÃ§Ã£o.")
                if not selected_providers:
                    st.warning("âš ï¸ Selecione pelo menos um provedor para comparaÃ§Ã£o.")
    
    with tab3:
        st.subheader("ğŸ§ª Testes de Conectividade")
        
        st.info("ğŸ”§ Teste a conectividade e configuraÃ§Ã£o de cada provedor LLM")
        
        providers_available = ["openai", "google", "openrouter", "deepseek"]
        
        for provider in providers_available:
            with st.expander(f"ğŸ§ª Testar {provider.upper()}"):
                test_question = st.text_input(f"Pergunta de teste para {provider}:", 
                                            value="OlÃ¡, vocÃª estÃ¡ funcionando?",
                                            key=f"test_{provider}")
                
                if st.button(f"ğŸ§ª Testar {provider.upper()}", key=f"btn_test_{provider}"):
                    with st.spinner(f"ğŸ§ª Testando {provider}..."):
                        try:
                            result = rag_system.llm_manager.generate_response(
                                test_question, 
                                provider_name=provider
                            )
                            
                            if result.get('success', False):
                                st.success(f"âœ… {provider.upper()} funcionando!")
                                st.info(f"â±ï¸ Tempo de resposta: {result.get('response_time', 0):.2f}s")
                                st.text_area(f"Resposta de {provider}:", 
                                           value=result.get('response', 'Sem resposta'),
                                           height=100, key=f"test_response_{provider}")
                            else:
                                st.error(f"âŒ Erro no {provider.upper()}: {result.get('error', 'Erro desconhecido')}")
                        
                        except Exception as e:
                            st.error(f"âŒ ExceÃ§Ã£o no {provider.upper()}: {str(e)}")

def privacy_interface(rag_system):
    """Interface de privacidade LGPD"""
    st.header("ğŸ”’ Sistema de Privacidade LGPD")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ” DetecÃ§Ã£o", "ğŸ“Š AnÃ¡lise", "ğŸ“‹ RelatÃ³rios"])
    
    with tab1:
        st.subheader("ğŸ” DetecÃ§Ã£o de Dados Pessoais")
        
        text_to_analyze = st.text_area("ğŸ“ Texto para AnÃ¡lise:", 
                                      placeholder="Cole o texto que deseja analisar...", 
                                      height=200)
        
        if st.button("ğŸ” Analisar Dados Pessoais"):
            if text_to_analyze:
                with st.spinner("ğŸ” Analisando dados pessoais..."):
                    try:
                        results = privacy_manager.detect_personal_data(text_to_analyze)
                        
                        if results.get('entities'):
                            st.subheader("âš ï¸ Dados Pessoais Detectados")
                            
                            for entity in results['entities']:
                                st.markdown(f"""
                                <div class="privacy-alert">
                                    <strong>Tipo:</strong> {entity.get('entity_type', 'N/A')}<br>
                                    <strong>Texto:</strong> {entity.get('text', 'N/A')}<br>
                                    <strong>ConfianÃ§a:</strong> {entity.get('confidence', 0):.2%}<br>
                                    <strong>PosiÃ§Ã£o:</strong> {entity.get('start', 0)}-{entity.get('end', 0)}
                                </div>
                                """, unsafe_allow_html=True)
                        else:
                            st.success("âœ… Nenhum dado pessoal detectado!")
                    
                    except Exception as e:
                        st.error(f"Erro na anÃ¡lise: {str(e)}")
            else:
                st.warning("âš ï¸ Digite um texto para anÃ¡lise.")
    
    with tab2:
        st.subheader("ğŸ“Š AnÃ¡lise de Riscos LGPD")
        
        st.info("ğŸ›¡ï¸ Sistema de anÃ¡lise de riscos em desenvolvimento...")
        
        # Placeholder para anÃ¡lise de riscos
        risk_level = st.select_slider("ğŸšï¸ NÃ­vel de Risco Simulado:", 
                                     options=["Baixo", "MÃ©dio", "Alto", "CrÃ­tico"],
                                     value="MÃ©dio")
        
        if risk_level == "Baixo":
            st.success("âœ… Risco Baixo: Conformidade adequada")
        elif risk_level == "MÃ©dio":
            st.warning("âš ï¸ Risco MÃ©dio: AtenÃ§Ã£o necessÃ¡ria")
        elif risk_level == "Alto":
            st.error("ğŸš¨ Risco Alto: AÃ§Ã£o imediata requerida")
        else:
            st.error("ğŸ”¥ Risco CrÃ­tico: ViolaÃ§Ã£o grave detectada")
    
    with tab3:
        st.subheader("ğŸ“‹ RelatÃ³rios de Compliance")
        
        if st.button("ğŸ“Š Gerar RelatÃ³rio"):
            st.markdown("""
            <div class="success-box">
                <h4>ğŸ“„ RelatÃ³rio de Compliance LGPD</h4>
                <p><strong>Data:</strong> {}</p>
                <p><strong>Status Geral:</strong> âœ… Conforme</p>
                <p><strong>Dados Processados:</strong> 0 registros</p>
                <p><strong>ViolaÃ§Ãµes Detectadas:</strong> 0</p>
                <p><strong>RecomendaÃ§Ãµes:</strong> Sistema operando dentro dos parÃ¢metros LGPD</p>
            </div>
            """.format(datetime.now().strftime("%d/%m/%Y %H:%M")), unsafe_allow_html=True)

def documents_interface(rag_system):
    """Interface de gerenciamento de documentos"""
    st.header("ğŸ“ Gerenciamento de Documentos")
    
    tab1, tab2, tab3 = st.tabs(["ğŸ“¤ Upload", "ğŸ“‹ Lista", "ğŸ” Busca"])
    
    with tab1:
        st.subheader("ğŸ“¤ Upload de Documentos")
        
        # SeleÃ§Ã£o de agente para a base de conhecimento
        agents = rag_system.agent_manager.get_all_agents()
        agent_options = {"Base Geral": None}
        agent_options.update({f"{agent['name']} (ID: {agent['id'][:8]}...)": agent['id'] for agent in agents})
        
        selected_agent = st.selectbox(
            "ğŸ¤– Selecionar Agente para Base de Conhecimento:", 
            list(agent_options.keys()),
            help="Escolha qual agente receberÃ¡ estes documentos em sua base de conhecimento"
        )
        agent_id = agent_options[selected_agent]
        
        if agent_id:
            agent = rag_system.agent_manager.get_agent_by_id(agent_id)
            if agent:
                st.info(f"ğŸ“š Documentos serÃ£o adicionados Ã  base do agente: **{agent['name']}**")
        else:
            st.info("ğŸ“š Documentos serÃ£o adicionados Ã  base geral do sistema")
        
        uploaded_files = st.file_uploader("Selecionar Arquivos:", 
                                        accept_multiple_files=True,
                                        type=['txt', 'pdf', 'docx', 'md'])
        
        if uploaded_files:
            st.markdown("### ğŸ“‹ Arquivos Selecionados:")
            for file in uploaded_files:
                st.write(f"ğŸ“„ {file.name} ({file.size} bytes)")
        
        if st.button("ğŸ“¤ Processar Uploads", type="primary"):
            if uploaded_files:
                with st.spinner("ğŸ“¤ Processando arquivos..."):
                    for file in uploaded_files:
                        # Simular processamento
                        content = file.read().decode('utf-8') if file.type == 'text/plain' else "ConteÃºdo processado"
                        
                        document = {
                            'name': file.name,
                            'content': content,
                            'type': file.type,
                            'size': file.size,
                            'uploaded_at': datetime.now().isoformat(),
                            'agent_id': agent_id,
                            'agent_name': agent['name'] if agent_id and agent else 'Base Geral'
                        }
                        
                        rag_system.documents.append(document)
                
                agent_name = agent['name'] if agent_id and agent else 'Base Geral'
                st.success(f"âœ… {len(uploaded_files)} arquivo(s) processado(s) com sucesso!")
                st.success(f"ğŸ“š Documentos adicionados Ã  base: **{agent_name}**")
                st.balloons()
                st.rerun()
            else:
                st.warning("âš ï¸ Selecione arquivos para upload.")
    
    with tab2:
        st.subheader("ğŸ“‹ Documentos Carregados")
        
        if rag_system.documents:
            # Filtro por agente
            agents = rag_system.agent_manager.get_all_agents()
            filter_options = ["Todos"] + ["Base Geral"] + [agent['name'] for agent in agents]
            
            selected_filter = st.selectbox("ğŸ” Filtrar por Agente:", filter_options)
            
            # Filtrar documentos
            filtered_docs = []
            for i, doc in enumerate(rag_system.documents):
                if selected_filter == "Todos":
                    filtered_docs.append((i, doc))
                elif selected_filter == "Base Geral" and not doc.get('agent_id'):
                    filtered_docs.append((i, doc))
                elif doc.get('agent_name') == selected_filter:
                    filtered_docs.append((i, doc))
            
            if filtered_docs:
                st.write(f"ğŸ“Š Mostrando {len(filtered_docs)} documento(s)")
                
                for i, doc in filtered_docs:
                    agent_info = doc.get('agent_name', 'Base Geral')
                    with st.expander(f"ğŸ“„ {doc['name']} - ğŸ¤– {agent_info}"):
                        col1, col2 = st.columns([3, 1])
                        
                        with col1:
                            st.write(f"**Tipo:** {doc.get('type', 'N/A')}")
                            st.write(f"**Tamanho:** {doc.get('size', 0)} bytes")
                            st.write(f"**Upload:** {doc.get('uploaded_at', 'N/A')}")
                            st.write(f"**Base de Conhecimento:** ğŸ¤– {agent_info}")
                            
                            if st.button(f"ğŸ‘ï¸ Visualizar", key=f"view_{i}"):
                                st.text_area("ConteÃºdo:", doc.get('content', '')[:500] + "...", height=100)
                        
                        with col2:
                            if st.button(f"ğŸ—‘ï¸ Remover", key=f"remove_{i}"):
                                rag_system.documents.pop(i)
                                st.success("ğŸ—‘ï¸ Documento removido!")
                                st.rerun()
            else:
                st.info(f"ğŸ“ Nenhum documento encontrado para: {selected_filter}")
        else:
            st.info("ğŸ“ Nenhum documento carregado ainda.")
    
    with tab3:
        st.subheader("ğŸ” Busca em Documentos")
        
        search_query = st.text_input("ğŸ” Termo de Busca:", placeholder="Digite para buscar...")
        
        if search_query:
            results = []
            for doc in rag_system.documents:
                if search_query.lower() in doc.get('content', '').lower():
                    results.append(doc)
            
            if results:
                st.write(f"ğŸ“Š Encontrados {len(results)} resultado(s):")
                for doc in results:
                    st.write(f"ğŸ“„ **{doc['name']}**")
            else:
                st.info("ğŸ” Nenhum resultado encontrado.")

def settings_interface(rag_system):
    """Interface de configuraÃ§Ãµes"""
    st.header("âš™ï¸ ConfiguraÃ§Ãµes do Sistema")
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ”‘ API Keys", "ğŸ§ª Testes", "ğŸ›ï¸ Geral", "ğŸ’¾ Backup"])
    
    with tab1:
        st.subheader("ğŸ”‘ ConfiguraÃ§Ã£o de Provedores LLM")
        
        # ConfiguraÃ§Ã£o das API Keys
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("### ğŸ¤– OpenAI")
            openai_key = st.text_input("OpenAI API Key:", type="password", 
                                      value=os.getenv('OPENAI_API_KEY', ''),
                                      key="openai_key")
            if openai_key:
                os.environ['OPENAI_API_KEY'] = openai_key
            
            st.markdown("### ğŸŒ OpenRouter")
            openrouter_key = st.text_input("OpenRouter API Key:", type="password",
                                          value=os.getenv('OPENROUTER_API_KEY', ''),
                                          key="openrouter_key")
            if openrouter_key:
                os.environ['OPENROUTER_API_KEY'] = openrouter_key
        
        with col2:
            st.markdown("### ğŸ§  Google Gemini")
            google_key = st.text_input("Google Gemini API Key:", type="password",
                                      value=os.getenv('GOOGLE_API_KEY', ''),
                                      key="google_key")
            if google_key:
                os.environ['GOOGLE_API_KEY'] = google_key
            
            st.markdown("### ğŸ”® DeepSeek")
            deepseek_key = st.text_input("DeepSeek API Key:", type="password",
                                        value=os.getenv('DEEPSEEK_API_KEY', ''),
                                        key="deepseek_key")
            if deepseek_key:
                os.environ['DEEPSEEK_API_KEY'] = deepseek_key
        
        # Status das API Keys
        st.markdown("---")
        st.subheader("ğŸ“Š Status das API Keys")
        
        keys_status = {
            "ğŸ¤– OpenAI": bool(os.getenv('OPENAI_API_KEY')),
            "ğŸ§  Google Gemini": bool(os.getenv('GOOGLE_API_KEY')),
            "ğŸŒ OpenRouter": bool(os.getenv('OPENROUTER_API_KEY')),
            "ğŸ”® DeepSeek": bool(os.getenv('DEEPSEEK_API_KEY'))
        }
        
        cols = st.columns(4)
        for i, (provider, configured) in enumerate(keys_status.items()):
            with cols[i]:
                status = "âœ… Ativa" if configured else "âŒ Inativa"
                color = "#28a745" if configured else "#dc3545"
                st.markdown(f"""
                <div style="text-align: center; padding: 10px; border: 1px solid {color}; border-radius: 5px; margin: 5px;">
                    <strong>{provider}</strong><br>
                    <span style="color: {color};">{status}</span>
                </div>
                """, unsafe_allow_html=True)
    
    with tab2:
        st.subheader("ğŸ§ª Testes de Conectividade")
        
        st.info("ğŸ” Teste a conectividade e funcionamento dos provedores LLM")
        
        # SeleÃ§Ã£o de provedores para teste
        providers_to_test = st.multiselect(
            "Selecione os provedores para testar:",
            ["openai", "google", "openrouter", "deepseek"],
            default=["openai"]
        )
        
        test_message = st.text_input("Mensagem de teste:", 
                                    value="OlÃ¡, este Ã© um teste de conectividade. Responda apenas 'OK'.")
        
        if st.button("ğŸš€ Executar Testes"):
            if providers_to_test:
                st.markdown("### ğŸ“Š Resultados dos Testes")
                
                for provider in providers_to_test:
                    with st.expander(f"ğŸ§ª Teste: {provider.upper()}"):
                        try:
                            # Testar conectividade
                            start_time = time.time()
                            
                            # Simular teste (vocÃª pode implementar teste real aqui)
                            messages = [{"role": "user", "content": test_message}]
                            
                            # Verificar se tem API key
                            key_map = {
                                'openai': 'OPENAI_API_KEY',
                                'google': 'GOOGLE_API_KEY', 
                                'openrouter': 'OPENROUTER_API_KEY',
                                'deepseek': 'DEEPSEEK_API_KEY'
                            }
                            
                            if not os.getenv(key_map.get(provider, '')):
                                st.error(f"âŒ API Key nÃ£o configurada para {provider}")
                                continue
                            
                            # Tentar gerar resposta
                            try:
                                response = rag_system.llm_manager.generate_response(
                                    messages, 
                                    provider=provider,
                                    model="gpt-3.5-turbo" if provider == "openai" else None
                                )
                                
                                end_time = time.time()
                                response_time = round(end_time - start_time, 2)
                                
                                st.success(f"âœ… **Sucesso!** Tempo: {response_time}s")
                                st.write(f"**Resposta:** {response}")
                                
                                # MÃ©tricas
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("â±ï¸ Tempo", f"{response_time}s")
                                with col2:
                                    st.metric("ğŸ“Š Status", "âœ… OK")
                                with col3:
                                    st.metric("ğŸ“ Caracteres", len(response))
                                    
                            except Exception as e:
                                st.error(f"âŒ **Erro na resposta:** {str(e)}")
                                
                        except Exception as e:
                            st.error(f"âŒ **Erro no teste:** {str(e)}")
            else:
                st.warning("âš ï¸ Selecione pelo menos um provedor para testar.")
        
        # Teste de comparaÃ§Ã£o rÃ¡pida
        st.markdown("---")
        st.subheader("âš¡ Teste RÃ¡pido Multi-LLM")
        
        if st.button("ğŸ”„ Comparar Todos os Provedores"):
            test_question = "Qual Ã© a capital do Brasil?"
            
            with st.spinner("ğŸ”„ Testando todos os provedores..."):
                results = {}
                
                for provider in ["openai", "google", "openrouter", "deepseek"]:
                    try:
                        key_map = {
                            'openai': 'OPENAI_API_KEY',
                            'google': 'GOOGLE_API_KEY', 
                            'openrouter': 'OPENROUTER_API_KEY',
                            'deepseek': 'DEEPSEEK_API_KEY'
                        }
                        
                        if os.getenv(key_map.get(provider, '')):
                            start_time = time.time()
                            
                            messages = [{"role": "user", "content": test_question}]
                            response = rag_system.llm_manager.generate_response(
                                messages, 
                                provider=provider
                            )
                            
                            end_time = time.time()
                            
                            results[provider] = {
                                'response': response,
                                'time': round(end_time - start_time, 2),
                                'status': 'success'
                            }
                        else:
                            results[provider] = {
                                'response': 'API Key nÃ£o configurada',
                                'time': 0,
                                'status': 'error'
                            }
                            
                    except Exception as e:
                        results[provider] = {
                            'response': f'Erro: {str(e)}',
                            'time': 0,
                            'status': 'error'
                        }
                
                # Mostrar resultados
                st.markdown("### ğŸ“Š Resultados da ComparaÃ§Ã£o")
                
                for provider, result in results.items():
                    with st.expander(f"ğŸ“± {provider.upper()} - {'âœ…' if result['status'] == 'success' else 'âŒ'}"):
                        if result['status'] == 'success':
                            col1, col2 = st.columns([3, 1])
                            with col1:
                                st.write(f"**Resposta:** {result['response']}")
                            with col2:
                                st.metric("â±ï¸ Tempo", f"{result['time']}s")
                        else:
                            st.error(result['response'])
    
    with tab3:
        st.subheader("ğŸ›ï¸ ConfiguraÃ§Ãµes Gerais")
        
        # ConfiguraÃ§Ãµes do modelo padrÃ£o
        col1, col2 = st.columns(2)
        
        with col1:
            default_model = st.selectbox("ğŸ¤– Modelo PadrÃ£o:", [
                "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo-preview", "gpt-4o-mini",
                "gemini-pro", "deepseek-chat"
            ], index=0)
            
            default_temperature = st.slider("ğŸŒ¡ï¸ Temperatura PadrÃ£o:", 0.0, 2.0, 0.7, 0.1)
        
        with col2:
            max_tokens = st.number_input("ğŸ“ Max Tokens:", min_value=100, max_value=4000, value=1000)
            
            debug_mode = st.checkbox("ğŸ› Modo Debug", value=False)
        
        # ConfiguraÃ§Ãµes avanÃ§adas
        st.markdown("---")
        st.subheader("ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas")
        
        col1, col2 = st.columns(2)
        
        with col1:
            timeout_duration = st.number_input("â±ï¸ Timeout (segundos):", min_value=5, max_value=300, value=30)
            retry_attempts = st.number_input("ğŸ”„ Tentativas de Retry:", min_value=1, max_value=10, value=3)
        
        with col2:
            enable_logging = st.checkbox("ğŸ“ Habilitar Logging", value=True)
            enable_cache = st.checkbox("ğŸ’¾ Habilitar Cache", value=True)
        
        if st.button("ğŸ’¾ Salvar ConfiguraÃ§Ãµes"):
            rag_system.settings.update({
                'model_name': default_model,
                'temperature': default_temperature,
                'max_tokens': max_tokens,
                'debug_mode': debug_mode,
                'timeout': timeout_duration,
                'retry_attempts': retry_attempts,
                'enable_logging': enable_logging,
                'enable_cache': enable_cache
            })
            st.success("âœ… ConfiguraÃ§Ãµes salvas com sucesso!")
    
    with tab4:
        st.subheader("ğŸ’¾ Backup e RestauraÃ§Ã£o")
        
        # InformaÃ§Ãµes do sistema
        st.markdown("### ğŸ“Š InformaÃ§Ãµes do Sistema")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ğŸ“„ Documentos", len(rag_system.documents))
        
        with col2:
            try:
                agents = rag_system.agent_manager.get_all_agents()
                st.metric("ğŸ¤– Agentes", len(agents))
            except:
                st.metric("ğŸ¤– Agentes", "N/A")
        
        with col3:
            configured_keys = sum([
                bool(os.getenv('OPENAI_API_KEY')),
                bool(os.getenv('GOOGLE_API_KEY')),
                bool(os.getenv('OPENROUTER_API_KEY')),
                bool(os.getenv('DEEPSEEK_API_KEY'))
            ])
            st.metric("ğŸ”‘ API Keys", f"{configured_keys}/4")
        
        st.markdown("---")
        
        # Export
        if st.button("ğŸ“¥ Exportar ConfiguraÃ§Ãµes"):
            config_data = {
                'settings': rag_system.settings,
                'documents_count': len(rag_system.documents),
                'api_keys_configured': configured_keys,
                'export_date': datetime.now().isoformat(),
                'version': '1.5.1-unified'
            }
            
            st.download_button(
                label="ğŸ’¾ Download ConfiguraÃ§Ãµes",
                data=json.dumps(config_data, indent=2),
                file_name=f"rag_config_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        
        # Import
        uploaded_config = st.file_uploader("ğŸ“¤ Importar ConfiguraÃ§Ãµes:", type=['json'])
        
        if uploaded_config and st.button("ğŸ“¥ Restaurar ConfiguraÃ§Ãµes"):
            try:
                config_data = json.load(uploaded_config)
                rag_system.settings.update(config_data.get('settings', {}))
                st.success("âœ… ConfiguraÃ§Ãµes restauradas com sucesso!")
                st.info(f"ğŸ“Š Importado de: {config_data.get('export_date', 'N/A')}")
            except Exception as e:
                st.error(f"âŒ Erro ao importar configuraÃ§Ãµes: {str(e)}")

if __name__ == "__main__":
    main() 